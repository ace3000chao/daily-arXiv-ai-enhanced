<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.HC](#cs.HC) [Total: 15]
- [cs.LG](#cs.LG) [Total: 49]
- [cs.AI](#cs.AI) [Total: 28]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare](https://arxiv.org/abs/2508.05722)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: PEACH是一个英语-阿拉伯语对齐的医疗文本平行语料库，包含51,671对句子，可用于语言学、翻译研究和自然语言处理。


<details>
  <summary>Details</summary>
Motivation: 为医疗领域的对比语言学、翻译研究和自然语言处理提供高质量的对齐语料库。

Method: 手动对齐的平行语料库构建，涵盖患者信息手册和教育材料。

Result: 语料库包含51,671对句子，约590,517英语和567,707阿拉伯语词，平均句子长度9.52至11.83词。

Conclusion: PEACH是一个公开可用的黄金标准语料库，支持多领域研究和应用。

Abstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic
corpus of healthcare texts encompassing patient information leaflets and
educational materials. The corpus contains 51,671 parallel sentences, totaling
approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths
vary between 9.52 and 11.83 words on average. As a manually aligned corpus,
PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,
translation studies, and natural language processing. It can be used to derive
bilingual lexicons, adapt large language models for domain-specific machine
translation, evaluate user perceptions of machine translation in healthcare,
assess patient information leaflets and educational materials' readability and
lay-friendliness, and as an educational resource in translation studies. PEACH
is publicly accessible.

</details>


### [2] [Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation](https://arxiv.org/abs/2508.05775)
*Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu*

Main category: cs.CL

TL;DR: 论文探讨了大语言模型（LLMs）在内容创作中的双重作用，既提供了有益应用，又可能产生有害内容，并系统综述了相关研究、防御策略及未来方向。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言生成和理解方面具有革命性能力，但同时也可能产生有毒或偏见内容，这提出了紧迫的社会技术挑战。

Method: 论文系统综述了近期关于LLMs无意毒性、对抗性越狱攻击和内容审核技术的研究，提出了统一的分类法，并分析了防御策略。

Result: 研究揭示了LLM安全性的演变趋势，指出了当前评估方法的局限性，并提出了未来研究方向。

Conclusion: 论文强调了开发稳健且符合伦理的语言技术的重要性，并呼吁进一步研究以解决LLMs的双重挑战。

Abstract: Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

</details>


### [3] [FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification](https://arxiv.org/abs/2508.05782)
*Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver*

Main category: cs.CL

TL;DR: 论文提出了一个细粒度对话事实验证基准FineDialFact，用于检测大语言模型生成的对话中的幻觉问题，并展示了结合Chain-of-Thought推理的方法能提升性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的对话中常包含事实错误或虚构信息（幻觉），现有检测方法过于粗粒度，需要更精细的验证方法。

Method: 构建FineDialFact基准数据集，基于公开对话数据集，并评估多种基线方法，尤其是结合Chain-of-Thought推理的方法。

Result: 实验表明，结合Chain-of-Thought推理的方法能提升性能，但在开放域对话数据集HybriDialogue上最佳F1分数仅为0.75，任务仍具挑战性。

Conclusion: FineDialFact为未来研究提供了挑战性基准，数据集和代码将公开。

Abstract: Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

</details>


### [4] [Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models](https://arxiv.org/abs/2508.05803)
*Abishek Thamma,Micha Heilbron*

Main category: cs.CL

TL;DR: 研究探讨了短暂记忆对语言学习的益处，发现其能提升语言模型性能，但意外地降低了人类阅读时间的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 验证短暂记忆是否如传统认知科学认为的那样有助于语言学习，尤其是在Transformer模型中的表现。

Method: 在Transformer语言模型上对比训练有和没有短暂记忆的版本，使用发展现实的训练集进行评估。

Result: 短暂记忆提升了语言建模性能，但降低了基于惊讶度的人类阅读时间预测准确性。

Conclusion: 短暂记忆对神经网络语言学习有益，但对行为预测无益。

Abstract: Human memory is fleeting. As words are processed, the exact wordforms that
make up incoming sentences are rapidly lost. Cognitive scientists have long
believed that this limitation of memory may, paradoxically, help in learning
language - an idea supported by classic connectionist modelling work. The rise
of Transformers appears to challenge this idea, as these models can learn
language effectively, despite lacking memory limitations or other architectural
recency biases. Here, we investigate the hypothesized benefit of fleeting
memory for language learning in tightly controlled experiments on transformer
language models. Training transformers with and without fleeting memory on a
developmentally realistic training set, we find that fleeting memory
consistently improves language learning (as quantified by both overall language
modelling performance and targeted syntactic evaluation) but, unexpectedly,
impairs surprisal-based prediction of human reading times. Interestingly,
follow up analyses revealed that this discrepancy - better language modeling,
yet worse reading time prediction - could not be accounted for by prior
explanations of why better language models sometimes fit human reading time
worse. Together, these results support a benefit of memory limitations on
neural network language learning - but not on predicting behavior.

</details>


### [5] ["Mirror" Language AI Models of Depression are Criterion-Contaminated](https://arxiv.org/abs/2508.05830)
*Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns*

Main category: cs.CL

TL;DR: 研究发现，基于语言的抑郁评估模型（Mirror模型）因“标准污染”导致效应量虚高，而Non-Mirror模型虽效应量较小但更具泛化性。


<details>
  <summary>Details</summary>
Motivation: 探讨Mirror模型和Non-Mirror模型在抑郁评估中的表现差异，揭示标准污染对模型泛化性的影响。

Method: 使用GPT-4、GPT-4o和LLaMA3-70B预测抑郁评分，比较Mirror模型（基于诊断访谈）和Non-Mirror模型（基于生活史访谈）的表现。

Result: Mirror模型效应量虚高（R2=0.80），Non-Mirror模型效应量较小但更稳定（R2=0.27），两者与自评抑郁症状的相关性相同（r≈0.54）。

Conclusion: Mirror模型因标准污染存在偏差，Non-Mirror模型更具泛化性和实用性，未来研究应关注其语义特征在心理评估中的应用。

Abstract: A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

</details>


### [6] [Discovering Properties of Inflectional Morphology in Neural Emergent Communication](https://arxiv.org/abs/2508.05843)
*Miles Gilberti,Shane Storks,Huteng Dai*

Main category: cs.CL

TL;DR: 该论文通过在小词汇量约束下重新解释属性-值重建游戏，模拟双分节，并设计了一种类似自然语言屈折形态的新设置，探索了新兴通信中与自然语言相似的形态特征。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过模拟自然语言的屈折形态特征，更深入地理解新兴通信与人类语言的相似性，尤其是双分节和形态融合现象。

Method: 在小词汇量约束下重新设计属性-值重建游戏，引入模拟屈折形态的新设置，开发新指标，并探索形态的拼接性和融合性。

Result: 实验发现，模拟的音位约束促进了拼接性形态，而新兴语言复制了自然语言融合语法属性的趋势。

Conclusion: 研究表明，新兴通信能够模拟自然语言的形态特征，为理解人类语言提供了新的视角。

Abstract: Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

</details>


### [7] [Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models](https://arxiv.org/abs/2508.05880)
*Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang*

Main category: cs.CL

TL;DR: 该论文探讨了大型语言模型（LLMs）如何通过认知维度进行情感推理，超越了传统的情感识别任务，并提出了一个名为CoRE的大规模基准来评估LLMs的认知推理能力。


<details>
  <summary>Details</summary>
Motivation: 情感计算是人工智能发展的重要领域，但现有研究多局限于基于离散情感标签的监督学习。本文旨在探索LLMs在情感推理中的认知维度，填补这一研究空白。

Method: 基于认知评估理论，作者设计了CoRE基准，通过大量实验分析LLMs在情感推理中的认知结构和维度。

Result: 研究发现不同LLMs表现出多样化的推理模式，揭示了认知评估维度在情感推理中的重要性。

Conclusion: 论文提出了一种新的情感推理评估方法，为LLMs在情感计算中的应用提供了更深入的理解和工具。

Abstract: Affective Computing has been established as a crucial field of inquiry to
advance the holistic development of Artificial Intelligence (AI) systems.
Foundation models -- especially Large Language Models (LLMs) -- have been
evaluated, trained, or instruction-tuned in several past works, to become
better predictors or generators of emotion. Most of these studies, however,
approach emotion-related tasks in a supervised manner, assessing or training
the capabilities of LLMs using discrete emotion labels associated with stimuli
(e.g., text, images, video, audio). Evaluation studies, in particular, have
often been limited to standard and superficial emotion-related tasks, such as
the recognition of evoked or expressed emotions. In this paper, we move beyond
surface-level emotion tasks to investigate how LLMs reason about emotions
through cognitive dimensions. Drawing from cognitive appraisal theory, we
examine whether LLMs produce coherent and plausible cognitive reasoning when
reasoning about emotionally charged stimuli. We introduce a large-scale
benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal
cognitive structures implicitly used by LLMs for emotional reasoning. Through a
plethora of evaluation experiments and analysis, we seek to answer: (a) Are
models more likely to implicitly rely on specific cognitive appraisal
dimensions?, (b) What cognitive dimensions are important for characterizing
specific emotions?, and, (c) Can the internal representations of different
emotion categories in LLMs be interpreted through cognitive appraisal
dimensions? Our results and analyses reveal diverse reasoning patterns across
different LLMs. Our benchmark and code will be made publicly available.

</details>


### [8] [Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05909)
*Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui*

Main category: cs.CL

TL;DR: 论文提出了一种名为SPS的轻量级无监督指标，用于评估检索摘要与生成模型的语义对齐，并在此基础上开发了xCompress框架，动态优化检索摘要。实验证明SPS能提升任务性能并揭示检索与生成的交互关系。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法难以单独评估检索的贡献，尤其是LLM作为读者时的提示敏感性。需要一种新指标来量化检索摘要与生成模型的语义对齐。

Method: 提出Spectrum Projection Score（SPS），通过比较生成标记形成的区域与读者子空间的主方向来评估语义对齐。基于SPS开发了xCompress框架，动态采样、排序和压缩检索摘要。

Result: 在五个QA基准测试和四种开源LLM上的实验表明，SPS能提升任务性能，并为检索与生成的交互提供了理论视角。

Conclusion: SPS是一种有效的轻量级指标，能动态优化检索摘要，提升生成性能，同时揭示了检索与生成的内在关系。

Abstract: Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

</details>


### [9] [Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale](https://arxiv.org/abs/2508.05938)
*Rafal Kocielnik,Min Kim,Penphob,Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 论文提出了一种三阶段流程，用于高效、低成本地检测文本中的亲社会性内容，结合人类与AI协作优化标注质量，并设计了两阶段推理系统以降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 亲社会性内容检测是一个新兴且重要的任务，但缺乏明确的定义和标注数据，需要新的方法来解决标注和部署问题。

Method: 采用三阶段流程：1) 基于小规模人工标注数据确定最佳LLM标注策略；2) 引入人类-AI协作循环优化任务定义；3) 训练两阶段推理系统，结合轻量级分类器和GPT-4o处理模糊实例。

Result: 通过该方法生成了10k高质量标注数据，推理成本降低约70%，同时保持高精度（约0.90）。

Conclusion: 研究表明，通过人类-AI协作、任务定义优化和部署感知的架构设计，可以为新兴的负责任AI任务提供可扩展的解决方案。

Abstract: Detecting prosociality in text--communication intended to affirm, support, or
improve others' behavior--is a novel and increasingly important challenge for
trust and safety systems. Unlike toxic content detection, prosociality lacks
well-established definitions and labeled data, requiring new approaches to both
annotation and deployment. We present a practical, three-stage pipeline that
enables scalable, high-precision prosocial content classification while
minimizing human labeling effort and inference costs. First, we identify the
best LLM-based labeling strategy using a small seed set of human-labeled
examples. We then introduce a human-AI refinement loop, where annotators review
high-disagreement cases between GPT-4 and humans to iteratively clarify and
expand the task definition-a critical step for emerging annotation tasks like
prosociality. This process results in improved label quality and definition
alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train
a two-stage inference system: a lightweight classifier handles high-confidence
predictions, while only $\sim$35\% of ambiguous instances are escalated to
GPT-4o. This architecture reduces inference costs by $\sim$70% while achieving
high precision ($\sim$0.90). Our pipeline demonstrates how targeted human-AI
interaction, careful task formulation, and deployment-aware architecture design
can unlock scalable solutions for novel responsible AI tasks.

</details>


### [10] [Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring](https://arxiv.org/abs/2508.05987)
*Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu*

Main category: cs.CL

TL;DR: 论文提出了一种名为ATOP的新方法，通过联合学习主题共享和主题特定特征，改进跨主题自动作文评分（AES）。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注通过源和目标主题的分布对齐提取主题共享特征，但忽略了主题特定特征，限制了评估关键特质（如主题一致性）的能力。

Method: ATOP通过优化可学习的主题感知提示（包含共享和特定组件）来从预训练语言模型中提取相关知识，并结合对抗训练和邻居分类器建模局部结构。

Result: 在ASAP++数据集上的实验表明，ATOP在整体和多特质作文评分上显著优于现有方法。

Conclusion: ATOP通过联合学习主题共享和特定特征，有效提升了跨主题AES的性能。

Abstract: Cross-topic automated essay scoring (AES) aims to develop a transferable
model capable of effectively evaluating essays on a target topic. A significant
challenge in this domain arises from the inherent discrepancies between topics.
While existing methods predominantly focus on extracting topic-shared features
through distribution alignment of source and target topics, they often neglect
topic-specific features, limiting their ability to assess critical traits such
as topic adherence. To address this limitation, we propose an Adversarial
TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns
topic-shared and topic-specific features to improve cross-topic AES. ATOP
achieves this by optimizing a learnable topic-aware prompt--comprising both
shared and specific components--to elicit relevant knowledge from pre-trained
language models (PLMs). To enhance the robustness of topic-shared prompt
learning and mitigate feature scale sensitivity introduced by topic alignment,
we incorporate adversarial training within a unified regression and
classification framework. In addition, we employ a neighbor-based classifier to
model the local structure of essay representations and generate pseudo-labels
for target-topic essays. These pseudo-labels are then used to guide the
supervised learning of topic-specific prompts tailored to the target topic.
Extensive experiments on the publicly available ASAP++ dataset demonstrate that
ATOP significantly outperforms existing state-of-the-art methods in both
holistic and multi-trait essay scoring. The implementation of our method is
publicly available at: https://anonymous.4open.science/r/ATOP-A271.

</details>


### [11] [Crisp Attention: Regularizing Transformers via Structured Sparsity](https://arxiv.org/abs/2508.06016)
*Sagar Gandhi,Vishal Gandhi*

Main category: cs.CL

TL;DR: 论文发现，在DistilBERT模型的注意力机制中引入结构化稀疏性后，模型在SST-2任务上的准确率显著提升，挑战了稀疏性会降低模型性能的普遍观点。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型中自注意力机制的二次计算成本问题，并探索稀疏性对模型性能的影响。

Method: 在DistilBERT模型的注意力机制中引入结构化稀疏性，并在SST-2情感分析任务上进行微调。

Result: 80%稀疏性的模型验证准确率达到91.59%，比密集基线提高了0.97%。

Conclusion: 稀疏性不仅是一种计算效率工具，还能通过隐式正则化提升Transformer模型的泛化能力和性能。

Abstract: The quadratic computational cost of the self-attention mechanism is a primary
challenge in scaling Transformer models. While attention sparsity is widely
studied as a technique to improve computational efficiency, it is almost
universally assumed to come at the cost of model accuracy. In this paper, we
report a surprising counter-example to this common wisdom. By introducing
structured, post-hoc sparsity to the attention mechanism of a DistilBERT model
during fine-tuning on the SST-2 sentiment analysis task, we find that model
accuracy improves significantly. Our model with 80\% attention sparsity
achieves a validation accuracy of 91.59\%, a 0.97\% absolute improvement over
the dense baseline. We hypothesize that this phenomenon is due to sparsity
acting as a powerful implicit regularizer, preventing the model from
overfitting by forcing it to make predictions with a more constrained and
robust set of features. Our work recasts attention sparsity not just as a tool
for computational efficiency, but as a potential method for improving the
generalization and performance of Transformer models.

</details>


### [12] [Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future](https://arxiv.org/abs/2508.06026)
*Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种改进的自奖励语言模型（Temporal Self-Rewarding Language Models），通过协调过去、现在和未来的模型输出来维持学习信号，解决了现有自奖励模型中对比样本差异逐渐缩小的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自奖励语言模型在同步改进选择和拒绝的响应时，逐渐缩小了对比样本的表示差异，影响了偏好学习的有效性。

Method: 提出双阶段框架：1）锚定拒绝（Anchored Rejection），固定初始模型的拒绝响应；2）未来引导选择（Future-Guided Chosen），动态筛选选择样本。

Result: 在多个模型家族和规模上实验表明，该方法显著优于基线，例如Llama3.1-8B在AlpacaEval 2.0上的胜率提升9.75。

Conclusion: 该方法不仅提升了性能，还在数学推理、知识问答和代码生成等任务上表现出更强的泛化能力。

Abstract: Self-Rewarding Language Models propose an architecture in which the Large
Language Models(LLMs) both generates responses and evaluates its own outputs
via LLM-as-a-Judge prompting, dynamically improving its generative capabilities
through iterative Direct Preference Optimization (DPO). However, our analysis
reveals a critical limitation in existing Self-Rewarding paradigms: the
synchronized improvement of chosen and rejected responses progressively narrows
the representational difference between contrasting samples, undermining
effective preference learning. We propose \textbf{Temporal Self-Rewarding
Language Models} that strategically coordinate past, present, and future model
generations to sustain learning signals. Our dual-phase framework introduces:
(1) \textit{Anchored Rejection} - fixing rejected responses using the past
initial model's outputs and (2) \textit{Future-Guided Chosen} - dynamically
curating chosen samples using next-generation model predictions. Extensive
experiments across three model families (Llama, Qwen, Mistral) and different
model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained
with our method compared to Self-Rewarding using same computation resources.
For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our
method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our
method also demonstrates superior out-of-distribution generalization across
mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code
generation (HumanEval) tasks, even though we do not specifically collect such
training data.

</details>


### [13] [Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings](https://arxiv.org/abs/2508.06030)
*Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar*

Main category: cs.CL

TL;DR: 论文提出了一种名为PEEK的方法，通过预训练的嵌入模型预测大型语言模型（LLM）的知识，避免了传统探测方法的高计算成本。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的随机性，传统探测其知识的方法计算成本高且耗时，因此需要一种更高效的方法。

Method: 利用预训练的嵌入模型（如文本或图嵌入）作为LLM的代理，通过线性解码层预测LLM的知识。

Result: 在3个维基百科数据集、4个LLM和7个嵌入模型上的实验表明，嵌入模型预测LLM知识的准确率高达90%。

Conclusion: PEEK方法能高效识别LLM的知识缺口，并揭示其内部归纳偏差，为LLM研究提供了新工具。

Abstract: Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

</details>


### [14] [EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](https://arxiv.org/abs/2508.06046)
*Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang*

Main category: cs.CL

TL;DR: 论文提出了Self-Evolving Pairwise Reasoning (EvolvR)框架，通过多角色策略生成对齐分数的Chain-of-Thought数据，并通过多智能体自过滤确保数据质量，最终提升故事评估和生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放任务（如故事评估）中表现有限，封闭模型提示工程适应性差，开源模型微调缺乏严谨推理能力。

Method: 提出EvolvR框架，基于成对比较，通过多角色策略自合成分数对齐的CoT数据，并通过多智能体自过滤确保数据质量。

Result: 在StoryER、HANNA和OpenMEVA三个基准测试中达到SOTA性能，作为奖励模型显著提升生成故事质量。

Conclusion: EvolvR框架通过自进化方法在故事评估和生成中表现出优越性。

Abstract: Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

</details>


### [15] [ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline](https://arxiv.org/abs/2508.06094)
*Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš*

Main category: cs.CL

TL;DR: 利用现代LLM作为计算创造力工具，通过多阶段管道ConlangCrafter实现端到端构造语言（conlang）的自动生成。


<details>
  <summary>Details</summary>
Motivation: 构造语言在艺术、哲学和国际交流中具有重要作用，但传统方法需要语言学专业知识。现代LLM为自动化生成提供了新可能。

Method: 提出ConlangCrafter，将语言设计分解为音系、形态、句法、词汇生成和翻译等模块化阶段，利用LLM的元语言推理能力和自反馈机制。

Result: 在一致性和类型多样性指标上表现良好，能够生成连贯且多样的conlang，无需人类语言学专业知识。

Conclusion: ConlangCrafter展示了LLM在构造语言生成中的潜力，为自动化语言设计提供了新工具。

Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

</details>


### [16] [Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs](https://arxiv.org/abs/2508.06103)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 论文提出了两种有效的《古兰经》抽取式问答方法，解决了复杂语言、独特术语和深层含义的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决《古兰经》问答任务中因复杂语言和独特术语带来的挑战。

Method: 1. 使用少量样本提示和指令调优的大语言模型（如Gemini和DeepSeek）；2. 开发了专门的阿拉伯语提示框架和强后处理系统。

Result: 大语言模型在阿拉伯语指令下表现优于传统微调模型，最佳配置的pAP10得分为0.637。

Conclusion: 基于提示的指令调优对低资源、语义丰富的问答任务有效。

Abstract: This paper presents two effective approaches for Extractive Question
Answering (QA) on the Quran. It addresses challenges related to complex
language, unique terminology, and deep meaning in the text. The second uses
few-shot prompting with instruction-tuned large language models such as Gemini
and DeepSeek. A specialized Arabic prompt framework is developed for span
extraction. A strong post-processing system integrates subword alignment,
overlap suppression, and semantic filtering. This improves precision and
reduces hallucinations. Evaluations show that large language models with Arabic
instructions outperform traditional fine-tuned models. The best configuration
achieves a pAP10 score of 0.637. The results confirm that prompt-based
instruction tuning is effective for low-resource, semantically rich QA tasks.

</details>


### [17] [You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures](https://arxiv.org/abs/2508.06105)
*Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang*

Main category: cs.CL

TL;DR: LogicRAG框架通过动态构建逻辑图解决传统GraphRAG的高成本和低效问题，提升检索和生成性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理超出知识范围的问题时会产生幻觉，传统GraphRAG方法因预构建图的成本和结构不灵活而效率低下。

Method: LogicRAG动态分解查询为子问题，构建逻辑依赖图，并通过拓扑排序和剪枝优化检索。

Result: 实验表明LogicRAG在性能和效率上优于现有方法。

Conclusion: LogicRAG通过动态逻辑结构显著提升了检索增强生成的效果和效率。

Abstract: Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

</details>


### [18] [AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models](https://arxiv.org/abs/2508.06124)
*Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee*

Main category: cs.CL

TL;DR: 论文提出AURA框架，通过多层次的Process Reward Models（PRMs）解决LLMs在逻辑推理中的安全问题，显著提升模型输出的安全性和逻辑完整性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs面临基于可操作性的安全风险，传统方法缺乏细粒度和主动性，无法可靠检测和干预关键推理步骤。

Method: AURA框架结合自省式自我批判、细粒度PRM评估和自适应安全感知解码，动态引导模型推理。

Result: 实证表明，AURA显著优于现有方法，提升模型输出的逻辑完整性和安全敏感性。

Conclusion: AURA为更安全、负责任的AI设定了新基准，推动了对齐敏感应用的发展。

Abstract: Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

</details>


### [19] [Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2508.06135)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为选择性反射蒸馏（SRD）的新框架，通过动态评估和选择高质量、学生模型兼容的训练数据，提升知识蒸馏（KD）的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有白盒知识蒸馏方法忽视训练数据质量和学生模型兼容性，限制了蒸馏效果。

Method: SRD利用学生模型的反馈动态筛选训练数据，并采用课程调度策略逐步引入数据。

Result: 实验表明SRD能显著提升蒸馏模型性能，并减少高达39%的训练时间。

Conclusion: 数据质量和兼容性是高效蒸馏的关键，SRD为压缩大语言模型提供了实用框架。

Abstract: Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

</details>


### [20] [Pragmatics beyond humans: meaning, communication, and LLMs](https://arxiv.org/abs/2508.06167)
*Vít Gvoždiak*

Main category: cs.CL

TL;DR: 论文重新定义语用学为动态接口，探讨大语言模型（LLMs）对传统语用理论的挑战，并提出人机通信（HMC）框架和概率语用学作为替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统语用学基于人类中心假设，不适合LLMs的预测性系统，需调整理论以适应生成式AI的通信需求。

Method: 通过分析LLMs对传统符号三分法的冲击，提出HMC框架和概率语用学（如理性言语行为框架），并讨论替代主义的三种形式及语境挫折现象。

Result: LLMs动摇了传统语用学的基础，概率语用学更适用于优化而非真值评估，同时揭示了人类中心偏见对LLM评估的扭曲。

Conclusion: 语用学理论需扩展以涵盖生成式AI的通信，强调人机交互中语境的动态共建。

Abstract: The paper reconceptualizes pragmatics not as a subordinate, third dimension
of meaning, but as a dynamic interface through which language operates as a
socially embedded tool for action. With the emergence of large language models
(LLMs) in communicative contexts, this understanding needs to be further
refined and methodologically reconsidered. The first section challenges the
traditional semiotic trichotomy, arguing that connectionist LLM architectures
destabilize established hierarchies of meaning, and proposes the Human-Machine
Communication (HMC) framework as a more suitable alternative. The second
section examines the tension between human-centred pragmatic theories and the
machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics
continue to dominate, it relies on human-specific assumptions ill-suited to
predictive systems like LLMs. Probabilistic pragmatics, particularly the
Rational Speech Act framework, offers a more compatible teleology by focusing
on optimization rather than truth-evaluation. The third section addresses the
issue of substitutionalism in three forms - generalizing, linguistic, and
communicative - highlighting the anthropomorphic biases that distort LLM
evaluation and obscure the role of human communicative subjects. Finally, the
paper introduces the concept of context frustration to describe the paradox of
increased contextual input paired with a collapse in contextual understanding,
emphasizing how users are compelled to co-construct pragmatic conditions both
for the model and themselves. These arguments suggest that pragmatic theory may
need to be adjusted or expanded to better account for communication involving
generative AI.

</details>


### [21] [Scaling Personality Control in LLMs with Big Five Scaler Prompts](https://arxiv.org/abs/2508.06149)
*Gunhee Cho,Yun-Gyung Cheong*

Main category: cs.CL

TL;DR: Big5-Scaler是一个基于提示的框架，用于控制大型语言模型的Big Five人格特质，无需额外训练即可实现细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过自然语言提示嵌入数值特质，实现对语言模型人格特质的可控调节。

Method: 通过将数值特质嵌入自然语言提示，Big5-Scaler框架实现了对LLMs的细粒度人格控制。

Result: 在不同任务中，Big5-Scaler表现出一致且可区分的人格特质，性能因提示类型和强度而异。

Conclusion: 简洁提示和较低特质强度是构建人格感知对话代理的有效方法。

Abstract: We present Big5-Scaler, a prompt-based framework for conditioning large
language models (LLMs) with controllable Big Five personality traits. By
embedding numeric trait values into natural language prompts, our method
enables fine-grained personality control without additional training. We
evaluate Big5-Scaler across trait expression, dialogue generation, and human
trait imitation tasks. Results show that it induces consistent and
distinguishable personality traits across models, with performance varying by
prompt type and scale. Our analysis highlights the effectiveness of concise
prompts and lower trait intensities, providing a efficient approach for
building personality-aware dialogue agents.

</details>


### [22] [EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations](https://arxiv.org/abs/2508.06196)
*Nizi Nazar,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: 论文提出了一种针对大型语言模型（LLMs）的情感智能（EI）四层分类法，并开发了EICAP-Bench基准测试。通过评估六种LLMs，发现Qwen2.5-Instruct表现最佳。进一步微调实验显示，仅Appraisal层有明显提升，揭示了现有预训练方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 情感智能（EI）在人类对齐的LLMs中是一个重要但未被充分探索的维度，需要系统化的评估和提升方法。

Method: 提出四层EI分类法，开发EICAP-Bench基准测试，评估六种LLMs，并通过LoRA适配器在UltraChat数据集上微调Qwen2.5模型。

Result: Qwen2.5-Instruct表现最佳，微调后仅Appraisal层显著提升。

Conclusion: 现有预训练方法在提升LLMs情感推理能力上存在局限，需针对性数据和建模策略。

Abstract: Emotional Intelligence (EI) is a critical yet underexplored dimension in the
development of human-aligned LLMs. To address this gap, we introduce a unified,
psychologically grounded four-layer taxonomy of EI tailored for large language
models (LLMs), encompassing emotional tracking, cause inference, appraisal, and
emotionally appropriate response generation. Building on this framework, we
present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to
evaluate EI capabilities in open-source LLMs across diverse linguistic and
cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma
(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,
identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential
for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and
Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,
instruction-tuned dialogue dataset, in both English and Arabic. Our statistical
analysis reveals that among the five EI layers, only the Appraisal layer shows
significant improvement through UC-based fine-tuning. These findings highlight
the limitations of existing pretraining and instruction-tuning paradigms in
equipping LLMs with deeper emotional reasoning and underscore the need for
targeted data and modeling strategies for comprehensive EI alignment.

</details>


### [23] [Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach](https://arxiv.org/abs/2508.06155)
*Renhan Zhang,Lian Lian,Zhen Qi,Guiran Liu*

Main category: cs.CL

TL;DR: 本文提出了一种可解释的偏见检测方法，用于识别大型语言模型输出中的隐含社会偏见，结合嵌套语义表示和上下文对比机制，通过注意力权重扰动分析模型对特定社会属性的敏感性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型生成过程中可能出现的隐含刻板印象问题，揭示不易通过显式语言特征捕捉的语义倾向。

Method: 结合嵌套语义表示与上下文对比机制，提取模型输出向量空间中的潜在偏见特征，并通过注意力权重扰动分析模型对特定社会属性术语的敏感性。

Result: 在StereoSet数据集上验证了方法的有效性，表现出高检测精度、语义一致性和上下文敏感性，能够准确识别语义相似文本间的偏见差异。

Conclusion: 该方法具有高可解释性，揭示了语言模型内部的偏见关联机制，为偏见检测提供了透明可靠的技术基础，适用于需要高可信生成内容的实际应用。

Abstract: This paper addresses the issue of implicit stereotypes that may arise during
the generation process of large language models. It proposes an interpretable
bias detection method aimed at identifying hidden social biases in model
outputs, especially those semantic tendencies that are not easily captured
through explicit linguistic features. The method combines nested semantic
representation with a contextual contrast mechanism. It extracts latent bias
features from the vector space structure of model outputs. Using attention
weight perturbation, it analyzes the model's sensitivity to specific social
attribute terms, thereby revealing the semantic pathways through which bias is
formed. To validate the effectiveness of the method, this study uses the
StereoSet dataset, which covers multiple stereotype dimensions including
gender, profession, religion, and race. The evaluation focuses on several key
metrics, such as bias detection accuracy, semantic consistency, and contextual
sensitivity. Experimental results show that the proposed method achieves strong
detection performance across various dimensions. It can accurately identify
bias differences between semantically similar texts while maintaining high
semantic alignment and output stability. The method also demonstrates high
interpretability in its structural design. It helps uncover the internal bias
association mechanisms within language models. This provides a more transparent
and reliable technical foundation for bias detection. The approach is suitable
for real-world applications where high trustworthiness of generated content is
required.

</details>


### [24] [One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging](https://arxiv.org/abs/2508.06163)
*Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: TADrop是一种自适应稀疏化策略，通过为每个参数张量分配定制化的稀疏率，优化模型合并中的参数干扰问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法采用统一的稀疏率，忽略了参数的结构和统计异质性，导致关键参数被误剪枝。TADrop旨在通过自适应稀疏化解决这一问题。

Method: TADrop根据参数张量的分布特性（如冗余度）为其分配不同的稀疏率，密集且冗余的张量被更激进地剪枝，稀疏且关键的张量被保留。

Result: 实验表明，TADrop在多种任务（视觉、语言、多模态）和模型（ViT、BEiT）中显著提升了合并方法的性能，平均性能提升2.0%。

Conclusion: TADrop通过自适应稀疏化有效缓解参数干扰，为高性能模型合并提供了新的基准。

Abstract: Model merging has emerged as a compelling data-free paradigm for multi-task
learning, enabling the fusion of multiple fine-tuned models into a single,
powerful entity. A key technique in merging methods is sparsification, which
prunes redundant parameters from task vectors to mitigate interference.
However, prevailing approaches employ a ``one-size-fits-all'' strategy,
applying a uniform sparsity ratio that overlooks the inherent structural and
statistical heterogeneity of model parameters. This often leads to a suboptimal
trade-off, where critical parameters are inadvertently pruned while less useful
ones are retained. To address this limitation, we introduce \textbf{TADrop}
(\textbf{T}ensor-wise \textbf{A}daptive \textbf{Drop}), an adaptive
sparsification strategy that respects this heterogeneity. Instead of a global
ratio, TADrop assigns a tailored sparsity level to each parameter tensor based
on its distributional properties. The core intuition is that tensors with
denser, more redundant distributions can be pruned aggressively, while sparser,
more critical ones are preserved. As a simple and plug-and-play module, we
validate TADrop by integrating it with foundational, classic, and SOTA merging
methods. Extensive experiments across diverse tasks (vision, language, and
multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and
significantly boosts their performance. For instance, when enhancing a leading
merging method, it achieves an average performance gain of 2.0\% across 8
ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter
interference by tailoring sparsification to the model's structure, offering a
new baseline for high-performance model merging.

</details>


### [25] [UR$^2$: Unify RAG and Reasoning through Reinforcement Learning](https://arxiv.org/abs/2508.06165)
*Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: UR2框架通过强化学习统一检索与推理，结合难度感知课程训练和混合知识访问策略，显著提升了任务适应性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）和基于验证奖励的强化学习（RLVR）方法孤立发展，限制了泛化能力和应用范围。

Method: 提出UR2框架，结合难度感知课程训练和混合知识访问策略，动态协调检索与推理。

Result: 在多个任务中表现优异，性能接近GPT-4o-mini和GPT-4.1-mini。

Conclusion: UR2为检索与推理的统一提供了通用解决方案，提升了模型在多样化任务中的表现。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities through two
complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances
knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),
which optimizes complex reasoning abilities. However, these two capabilities
are often developed in isolation, and existing efforts to unify them remain
narrow in scope-typically limited to open-domain QA with fixed retrieval
settings and task-specific assumptions. This lack of integration constrains
generalization and limits the applicability of RAG-RL methods to broader
domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a
general framework that unifies retrieval and reasoning through reinforcement
learning. UR2 introduces two key contributions: a difficulty-aware curriculum
training that selectively invokes retrieval only for challenging problems, and
a hybrid knowledge access strategy combining domain-specific offline corpora
with LLM-generated summaries. These components are designed to enable dynamic
coordination between retrieval and reasoning, improving adaptability across a
diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,
and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B
and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,
achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several
benchmarks. We have released all code, models, and data at
https://github.com/Tsinghua-dhy/UR2.

</details>


### [26] [Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime](https://arxiv.org/abs/2508.06178)
*Hugo Abonizio,Thales Almeida,Roberto Lotufo,Rodrigo Nogueira*

Main category: cs.CL

TL;DR: 研究探讨了如何向大语言模型（LLM）注入少量非结构化信息，并分析了其与灾难性遗忘现象的关系。通过实验比较了不同数据增强方法，发现多样性文本能显著提升新知识学习能力，同时揭示了小数据场景下的遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在少量数据下更新知识的挑战，避免灾难性遗忘，并探索高效的知识注入方法。

Method: 使用新闻数据集评估知识获取能力，比较了持续预训练和数据增强方法，包括多样性提示生成合成数据。

Result: 多样性文本显著提升新知识学习能力；RAG方法在小数据下表现较差；模型可生成有效合成数据用于自我更新。

Conclusion: 多样性数据增强是高效知识注入的关键，同时需平衡新知识学习与旧知识保留；模型自我生成数据为未来研究提供了方向。

Abstract: Large language models (LLMs) often require vast amounts of text to
effectively acquire new knowledge. While continuing pre-training on large
corpora or employing retrieval-augmented generation (RAG) has proven
successful, updating an LLM with only a few thousand or million tokens remains
challenging. In this work, we investigate the task of injecting small,
unstructured information into LLMs and its relation to the catastrophic
forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap
with the model's pre-training data -- to evaluate the knowledge acquisition by
probing the model with question-answer pairs related the learned information.
Starting from a continued pre-training baseline, we explored different
augmentation algorithms to generate synthetic data to improve the knowledge
acquisition capabilities. Our experiments show that simply continuing
pre-training on limited data yields modest improvements, whereas exposing the
model to diverse textual variations significantly improves the learning of new
facts -- particularly with methods that induce greater variability through
diverse prompting. Furthermore, we shed light on the forgetting phenomenon in
small-data regimes, illustrating the delicate balance between learning new
content and retaining existing capabilities. We also confirm the sensitivity of
RAG-based approaches for knowledge injection, which often lead to greater
degradation on control datasets compared to parametric methods. Finally, we
demonstrate that models can generate effective synthetic training data
themselves, suggesting a pathway toward self-improving model updates. All code
and generated data used in our experiments are publicly available, providing a
resource for studying efficient knowledge injection in LLMs with limited data
at https://github.com/hugoabonizio/knowledge-injection-methods.

</details>


### [27] [DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration](https://arxiv.org/abs/2508.06186)
*Ali Sarabadani,Maryam Abdollahi Shamami,Hamidreza Sadeghsalehi,Borhan Asadi,Saba Hesaraki*

Main category: cs.CL

TL;DR: DKG-LLM框架通过动态知识图谱与Grok 3大语言模型结合，提出了一种创新的医疗诊断和个性化治疗推荐方法，显著提升了诊断和治疗推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在自然语言理解方面取得了显著进展，本研究旨在利用动态知识图谱（DKG）增强LLMs在医疗领域的应用，解决复杂医疗数据的处理问题。

Method: 采用自适应语义融合算法（ASFA），结合贝叶斯推理和图优化技术，动态构建和更新知识图谱，整合异构医疗数据（如临床报告和PubMed文章）和患者记录。

Result: DKG-LLM在MIMIC-III和PubMed数据集上的评估显示，诊断准确率为84.19%，治疗推荐准确率为89.63%，语义覆盖率为93.48%。

Conclusion: DKG-LLM是一种可靠且具有变革性的工具，能够处理噪声数据和复杂多症状疾病，并通过医生反馈进行学习。

Abstract: Large Language Models (LLMs) have grown exponentially since the release of
ChatGPT. These models have gained attention due to their robust performance on
various tasks, including language processing tasks. These models achieve
understanding and comprehension of tasks by training billions of parameters.
The development of these models is a transformative force in enhancing natural
language understanding and has taken a significant step towards artificial
general intelligence (AGI). In this study, we aim to present the DKG-LLM
framework. The DKG-LLM framework introduces a groundbreaking approach to
medical diagnosis and personalized treatment recommendations by integrating a
dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the
Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data
(including clinical reports and PubMed articles) and patient records
dynamically generate a knowledge graph consisting of 15,964 nodes in 13
distinct types (e.g., diseases, symptoms, treatments, patient profiles) and
127,392 edges in 26 relationship types (e.g., causal, therapeutic,
association). ASFA utilizes advanced probabilistic models, Bayesian inference,
and graph optimization to extract semantic information, dynamically updating
the graph with approximately 150 new nodes and edges in each data category
while maintaining scalability with up to 987,654 edges. Real-world datasets,
including MIMIC-III and PubMed, were utilized to evaluate the proposed
architecture. The evaluation results show that DKG-LLM achieves a diagnostic
accuracy of 84.19%. The model also has a treatment recommendation accuracy of
89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and
transformative tool that handles noisy data and complex multi-symptom diseases,
along with feedback-based learning from physician input.

</details>


### [28] [Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation](https://arxiv.org/abs/2508.06194)
*Lai Jiang,Yuekang Li,Xiaohan Zhang,Youtao Ding,Li Pan*

Main category: cs.CL

TL;DR: SceneJailEval提出了一种场景自适应的多维度框架，用于精确评估LLM越狱行为，解决了现有方法在场景适应性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有越狱评估方法多为二元分类或多维度统一标准，无法量化危害强度且存在场景不匹配问题。

Method: 提出场景自适应的多维度框架SceneJailEval，并构建包含14种场景的数据集。

Result: SceneJailEval在全面场景数据集上F1得分0.917（比现有方法高6%），在JBB上0.995（高3%）。

Conclusion: SceneJailEval在异构场景中表现优异，验证了其优势。

Abstract: Precise jailbreak evaluation is vital for LLM red teaming and jailbreak
research. Current approaches employ binary classification ( e.g., string
matching, toxic text classifiers, LLM-driven methods), yielding only "yes/no"
labels without quantifying harm intensity. Existing multi-dimensional
frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)
apply uniform evaluation criteria across scenarios, resulting in
scenario-specific mismatches--for instance, "Relative Truthfulness" is
irrelevant to "hate speech"--which compromise evaluation precision. To tackle
these limitations, we introduce SceneJailEval, with key contributions: (1) A
groundbreaking scenario-adaptive multi-dimensional framework for jailbreak
evaluation, overcoming the critical "one-size-fits-all" constraint of existing
multi-dimensional methods, and featuring strong extensibility to flexibly adapt
to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset
with diverse jailbreak variants and regional cases, filling the long-standing
gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)
SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on
our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over
prior SOTA), surpassing accuracy limits of existing evaluation methods in
heterogeneous scenarios and confirming its advantage.

</details>


### [29] [Classification is a RAG problem: A case study on hate speech detection](https://arxiv.org/abs/2508.06204)
*Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen*

Main category: cs.CL

TL;DR: 论文提出了一种基于检索增强生成（RAG）的内容分类方法，用于灵活、透明的政策驱动内容审核。


<details>
  <summary>Details</summary>
Motivation: 传统分类系统需要频繁重新训练以适应政策变化，成本高且不灵活。

Method: 使用检索增强生成（RAG）将分类任务从预训练参数依赖转变为基于上下文知识检索的评估。

Result: 实验表明，该方法在仇恨言论检测中表现优异，支持动态政策更新且无需重新训练。

Conclusion: RAG方法使分类更灵活、透明，适用于内容审核及其他分类问题。

Abstract: Robust content moderation requires classification systems that can quickly
adapt to evolving policies without costly retraining. We present classification
using Retrieval-Augmented Generation (RAG), which shifts traditional
classification tasks from determining the correct category in accordance with
pre-trained parameters to evaluating content in relation to contextual
knowledge retrieved at inference. In hate speech detection, this transforms the
task from "is this hate speech?" to "does this violate the hate speech policy?"
  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates
this approach and offers three key advantages: (1) robust classification
accuracy comparable to leading commercial systems, (2) inherent explainability
via retrieved policy segments, and (3) dynamic policy updates without model
retraining. Through three experiments, we demonstrate strong baseline
performance and show that the system can apply fine-grained policy control by
correctly adjusting protection for specific identity groups without requiring
retraining or compromising overall performance. These findings establish that
RAG can transform classification into a more flexible, transparent, and
adaptable process for content moderation and wider classification problems.

</details>


### [30] [InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?](https://arxiv.org/abs/2508.06220)
*Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu*

Main category: cs.CL

TL;DR: InfoCausalQA是一个新的基准测试，用于评估基于信息图的因果推理能力，发现当前视觉语言模型在计算和语义因果推理方面表现有限。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在因果推理方面的能力，填补多模态环境中因果推理研究的空白。

Method: 通过手动收集494对信息图-文本数据，使用GPT-4生成1,482个高质量选择题QA对，并进行人工修订。

Result: 当前视觉语言模型在计算和语义因果推理方面表现较差，与人类存在显著差距。

Conclusion: InfoCausalQA揭示了提升多模态AI系统因果推理能力的必要性。

Abstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive
capabilities in perception and reasoning. However, the ability to perform
causal inference -- a core aspect of human cognition -- remains underexplored,
particularly in multimodal settings. In this study, we introduce InfoCausalQA,
a novel benchmark designed to evaluate causal reasoning grounded in
infographics that combine structured visual data with textual context. The
benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning
based on inferred numerical trends, while Task 2 targets semantic causal
reasoning involving five types of causal relations: cause, effect,
intervention, counterfactual, and temporal. We manually collected 494
infographic-text pairs from four public sources and used GPT-4o to generate
1,482 high-quality multiple-choice QA pairs. These questions were then
carefully revised by humans to ensure they cannot be answered based on
surface-level cues alone but instead require genuine visual grounding. Our
experimental results reveal that current VLMs exhibit limited capability in
computational reasoning and even more pronounced limitations in semantic causal
reasoning. Their significantly lower performance compared to humans indicates a
substantial gap in leveraging infographic-based information for causal
inference. Through InfoCausalQA, we highlight the need for advancing the causal
reasoning abilities of multimodal AI systems.

</details>


### [31] [Large Language Model Data Generation for Enhanced Intent Recognition in German Speech](https://arxiv.org/abs/2508.06277)
*Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter*

Main category: cs.CL

TL;DR: 本文提出了一种结合Whisper ASR模型和Transformer语言模型的新方法，用于识别老年德语使用者的语音意图，并通过合成数据提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有意图识别方法多针对英语和短命令，本文旨在解决老年德语使用者的语音意图识别问题。

Method: 结合Whisper ASR模型和基于Transformer的语言模型，利用LeoLM、Llama3和ChatGPT生成的合成文本数据进行训练。

Result: 合成数据显著提升了分类性能和鲁棒性，LeoLM在德语意图识别中表现优于ChatGPT。

Conclusion: 生成式AI可有效填补低资源领域的数据缺口，方法透明且可复现。

Abstract: Intent recognition (IR) for speech commands is essential for artificial
intelligence (AI) assistant systems; however, most existing approaches are
limited to short commands and are predominantly developed for English. This
paper addresses these limitations by focusing on IR from speech by elderly
German speakers. We propose a novel approach that combines an adapted Whisper
ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based
language models trained on synthetic text datasets generated by three
well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To
evaluate the robustness of our approach, we generate synthetic speech with a
text-to-speech model and conduct extensive cross-dataset testing. Our results
show that synthetic LLM-generated data significantly boosts classification
performance and robustness to different speaking styles and unseen vocabulary.
Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the
much larger ChatGPT (175B) in dataset quality for German intent recognition.
Our approach demonstrates that generative AI can effectively bridge data gaps
in low-resource domains. We provide detailed documentation of our data
generation and training process to ensure transparency and reproducibility.

</details>


### [32] [Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC](https://arxiv.org/abs/2508.06309)
*Ruichong Zhang*

Main category: cs.CL

TL;DR: MDIR是一种基于矩阵分析和大偏差理论的新方法，用于检测大型语言模型（LLM）的抄袭行为，解决了现有方法在权重对应重建、统计显著性计算和误报方面的不足。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型（LLM）的知识产权（IP）问题日益突出，现有抄袭检测方法在权重对应重建、统计显著性计算和误报方面存在不足。

Method: 提出Matrix-Driven Instant Review（MDIR），利用矩阵分析和大偏差理论，专注于权重相似性，无需完整模型推理。

Result: 实验表明，MDIR能可靠检测经过随机排列和万亿级token持续预训练等变换的抄袭行为，且单台PC一小时内即可完成检测。

Conclusion: MDIR是一种高效、准确的LLM抄袭检测方法，解决了现有技术的局限性。

Abstract: In recent years, concerns about intellectual property (IP) in large language
models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct
weight copying, upcycling, pruning, or continual pretraining) and claiming
authorship without properly attributing to the original license, is a serious
misconduct that can lead to significant financial and reputational harm to the
original developers. However, existing methods for detecting LLM plagiarism
fall short in key areas. They fail to accurately reconstruct weight
correspondences, lack the ability to compute statistical significance measures
such as $p$-values, and may mistakenly flag models trained on similar data as
being related. To address these limitations, we propose Matrix-Driven Instant
Review (MDIR), a novel method that leverages matrix analysis and Large
Deviation Theory. MDIR achieves accurate reconstruction of weight
relationships, provides rigorous $p$-value estimation, and focuses exclusively
on weight similarity without requiring full model inference. Experimental
results demonstrate that MDIR reliably detects plagiarism even after extensive
transformations, such as random permutations and continual pretraining with
trillions of tokens. Moreover, all detections can be performed on a single PC
within an hour, making MDIR both efficient and accessible.

</details>


### [33] [Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering](https://arxiv.org/abs/2508.06345)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang*

Main category: cs.CL

TL;DR: 论文提出DynamicTRF框架，通过动态选择适合的图表示形式（TRF）和引入图响应效率（GRE）指标，显著提升了大型多模态模型（LMMs）在零样本图问答任务中的准确性和简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用单一图表示形式（TRF），忽略了不同模型或任务的特定需求，导致回答不准确或冗长。

Method: 分析现有TRF的优缺点，设计适合零样本图问答的TRF集合（$F_{ZS}$），引入GRE指标衡量性能与简洁性，开发DynamicTRF框架动态选择最佳TRF。

Result: 在7个领域内算法图问答任务和2个领域外下游任务中，DynamicTRF显著提升了LMMs的零样本图问答准确性。

Conclusion: DynamicTRF通过动态TRF选择和GRE优化，有效解决了现有方法的局限性，提升了图问答任务的性能。

Abstract: Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities
in diverse domain question-answering (QA) tasks, including graph QA that
involves complex graph topologies. However, most current approaches use only a
single type of graph representation, namely Topology Representation Form (TRF),
such as prompt-unified text descriptions or style-fixed visual styles. Those
"one-size-fits-all" approaches fail to consider the specific preferences of
different models or tasks, often leading to incorrect or overly long responses.
To address this, we first analyze the characteristics and weaknesses of
existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to
zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency
(GRE), which measures the balance between the performance and the brevity in
graph QA. Built on these, we develop the DynamicTRF framework, which aims to
improve both the accuracy and conciseness of graph QA. To be specific,
DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based
on their GRE scores, to probe the question-specific TRF preferences. Then it
trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from
$F_{ZS}$ for each question during the inference. Extensive experiments across 7
in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show
that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms
of accuracy

</details>


### [34] [Cyberbullying Detection via Aggression-Enhanced Prompting](https://arxiv.org/abs/2508.06360)
*Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 研究探讨了通过将攻击性检测作为辅助任务，增强大语言模型在社交媒体网络欺凌检测中的性能。实验表明，基于攻击性预测的提示增强方法优于标准微调。


<details>
  <summary>Details</summary>
Motivation: 网络欺凌检测因表达隐晦多样而具有挑战性，研究旨在通过辅助任务提升模型性能。

Method: 采用指令调优的大语言模型，评估零样本、少样本、独立LoRA微调和多任务学习策略，并提出基于攻击性预测的提示增强方法。

Result: 提示增强方法在性能上优于标准LoRA微调，表明攻击性信息能显著提升检测效果。

Conclusion: 辅助任务（如攻击性检测）可提升大语言模型在安全关键应用中的泛化能力。

Abstract: Detecting cyberbullying on social media remains a critical challenge due to
its subtle and varied expressions. This study investigates whether integrating
aggression detection as an auxiliary task within a unified training framework
can enhance the generalisation and performance of large language models (LLMs)
in cyberbullying detection. Experiments are conducted on five aggression
datasets and one cyberbullying dataset using instruction-tuned LLMs. We
evaluated multiple strategies: zero-shot, few-shot, independent LoRA
fine-tuning, and multi-task learning (MTL). Given the inconsistent results of
MTL, we propose an enriched prompt pipeline approach in which aggression
predictions are embedded into cyberbullying detection prompts to provide
contextual augmentation. Preliminary results show that the enriched prompt
pipeline consistently outperforms standard LoRA fine-tuning, indicating that
aggression-informed context significantly boosts cyberbullying detection. This
study highlights the potential of auxiliary tasks, such as aggression
detection, to improve the generalisation of LLMs for safety-critical
applications on social networks.

</details>


### [35] [Evaluating Style-Personalized Text Generation: Challenges and Directions](https://arxiv.org/abs/2508.06374)
*Anubhav Jangra,Bahareh Sarrafzadeh,Adrian de Wynter,Silviu Cucerzan,Sujay Kumar Jauhar*

Main category: cs.CL

TL;DR: 论文探讨了低资源作者风格个性化文本生成中的评估问题，质疑BLEU和ROUGE等传统指标的有效性，并提出使用风格嵌入和LLM-as-judge等新评估范式。


<details>
  <summary>Details</summary>
Motivation: 现有研究在低资源作者风格个性化文本生成领域的评估探索有限，传统指标可能不足以全面评估任务效果。

Method: 通过构建风格判别基准，覆盖八种写作任务和三种设置（领域判别、作者归属、LLM个性化与非个性化判别），评估多种指标及其组合。

Result: 研究证明，采用多样化的评估指标组合能更有效地评估风格个性化文本生成。

Conclusion: 建议采用多样化的评估指标组合来全面评估风格个性化文本生成任务。

Abstract: While prior research has built tools and benchmarks towards style
personalized text generation, there has been limited exploration of evaluation
in low-resource author style personalized text generation space. Through this
work, we question the effectiveness of the widely adopted evaluation metrics
like BLEU and ROUGE, and explore other evaluation paradigms such as style
embeddings and LLM-as-judge to holistically evaluate the style personalized
text generation task. We evaluate these metrics and their ensembles using our
style discrimination benchmark, that spans eight writing tasks, and evaluates
across three settings, domain discrimination, authorship attribution, and LLM
personalized vs non-personalized discrimination. We provide conclusive evidence
to adopt ensemble of diverse evaluation metrics to effectively evaluate style
personalized text generation.

</details>


### [36] [LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing](https://arxiv.org/abs/2508.06388)
*Lanlan Qiu,Xiao Pu,Yeqi Feng,Tianxing He*

Main category: cs.CL

TL;DR: 论文提出了ChatAnime数据集，结合角色扮演和情感支持能力，评估LLMs在动漫角色情感支持对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究未结合LLMs的角色扮演和情感支持能力，ChatAnime填补了这一空白，以动漫角色为案例进行研究。

Method: 选择20个热门动漫角色，设计60个情感场景问题，收集40名中国动漫爱好者和10个LLMs的对话数据，评估系统包含9个细粒度指标。

Result: 表现最佳的LLMs在角色扮演和情感支持上超越人类，但人类在回答多样性上仍占优。

Conclusion: ChatAnime为未来优化LLMs在情感支持角色扮演中的研究提供了资源和见解。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing conversations and providing emotional support as separate research
directions. However, there remains a significant research gap in combining
these capabilities to enable emotionally supportive interactions with virtual
characters. To address this research gap, we focus on anime characters as a
case study because of their well-defined personalities and large fan bases.
This choice enables us to effectively evaluate how well LLMs can provide
emotional support while maintaining specific character traits. We introduce
ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We
first thoughtfully select 20 top-tier characters from popular anime communities
and design 60 emotion-centric real-world scenario questions. Then, we execute a
nationwide selection process to identify 40 Chinese anime enthusiasts with
profound knowledge of specific characters and extensive experience in
role-playing. Next, we systematically collect two rounds of dialogue data from
10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP
performance of LLMs, we design a user experience-oriented evaluation system
featuring 9 fine-grained metrics across three dimensions: basic dialogue,
role-playing and emotional support, along with an overall metric for response
diversity. In total, the dataset comprises 2,400 human-written and 24,000
LLM-generated answers, supported by over 132,000 human annotations.
Experimental results show that top-performing LLMs surpass human fans in
role-playing and emotional support, while humans still lead in response
diversity. We hope this work can provide valuable resources and insights for
future research on optimizing LLMs in ESRP. Our datasets are available at
https://github.com/LanlanQiu/ChatAnime.

</details>


### [37] [Quantifying Conversation Drift in MCP via Latent Polytope](https://arxiv.org/abs/2508.06418)
*Haoran Shi,Hongwei Yao,Shuo Shao,Shaopeng Jiao,Ziqi Peng,Zhan Qin,Cong Wang*

Main category: cs.CL

TL;DR: SecMCP框架通过动态检测对话漂移，解决了MCP的安全和隐私风险，提升了LLM的安全性。


<details>
  <summary>Details</summary>
Motivation: MCP的非隔离执行环境引入了安全和隐私风险，现有防御措施不足。

Method: SecMCP利用潜在多面体空间建模LLM激活向量，检测对话动态异常。

Result: 在多个LLM和数据集上验证，AUROC分数超过0.915，系统实用性良好。

Conclusion: SecMCP有效解决了MCP的安全威胁，提供了量化对话漂移的新方法。

Abstract: The Model Context Protocol (MCP) enhances large language models (LLMs) by
integrating external tools, enabling dynamic aggregation of real-time data to
improve task execution. However, its non-isolated execution context introduces
critical security and privacy risks. In particular, adversarially crafted
content can induce tool poisoning or indirect prompt injection, leading to
conversation hijacking, misinformation propagation, or data exfiltration.
Existing defenses, such as rule-based filters or LLM-driven detection, remain
inadequate due to their reliance on static signatures, computational
inefficiency, and inability to quantify conversational hijacking. To address
these limitations, we propose SecMCP, a secure framework that detects and
quantifies conversation drift, deviations in latent space trajectories induced
by adversarial external knowledge. By modeling LLM activation vectors within a
latent polytope space, SecMCP identifies anomalous shifts in conversational
dynamics, enabling proactive detection of hijacking, misleading, and data
exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,
Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),
demonstrating robust detection with AUROC scores exceeding 0.915 while
maintaining system usability. Our contributions include a systematic
categorization of MCP security threats, a novel latent polytope-based
methodology for quantifying conversation drift, and empirical validation of
SecMCP's efficacy.

</details>


### [38] [Memp: Exploring Agent Procedural Memory](https://arxiv.org/abs/2508.06433)
*Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 论文提出Memp方法，通过提炼过往代理轨迹为细粒度指令和高级抽象，赋予代理可学习、可更新的终身程序记忆，提升任务成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的代理程序记忆脆弱，依赖手动设计或静态参数，需要可学习、可更新的终身记忆机制。

Method: 提出Memp方法，将代理轨迹提炼为细粒度指令和高级抽象，研究构建、检索和更新策略，并动态更新记忆内容。

Result: 实验表明，随着记忆库优化，代理在类似任务中成功率和效率持续提升；强模型构建的记忆迁移至弱模型仍能显著提升性能。

Conclusion: Memp方法有效提升代理程序记忆的灵活性和性能，支持终身学习和迁移。

Abstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they
suffer from brittle procedural memory that is manually engineered or entangled
in static parameters. In this work, we investigate strategies to endow agents
with a learnable, updatable, and lifelong procedural memory. We propose Memp
that distills past agent trajectories into both fine-grained, step-by-step
instructions and higher-level, script-like abstractions, and explore the impact
of different strategies for Build, Retrieval, and Update of procedural memory.
Coupled with a dynamic regimen that continuously updates, corrects, and
deprecates its contents, this repository evolves in lockstep with new
experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as
the memory repository is refined, agents achieve steadily higher success rates
and greater efficiency on analogous tasks. Moreover, procedural memory built
from a stronger model retains its value: migrating the procedural memory to a
weaker model yields substantial performance gains.

</details>


### [39] [Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages](https://arxiv.org/abs/2508.06435)
*Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain*

Main category: cs.CL

TL;DR: LLMs通过少量语言微调可实现跨语言主题检测，多语言微调有助于立场分类，轻量干预可纠正预训练偏见。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在少量语言微调后是否能迁移到未见语言，并探讨预训练偏见的纠正方法。

Method: 在单语、双语或多语数据集上微调轻量LLaMA模型，用于13种语言的移民相关推文分类。

Result: 少量语言微调即可实现跨语言主题检测，多语言微调提升立场分类效果；轻量干预显著纠正偏见。

Conclusion: 跨语言能力无需大量多语言训练，轻量干预可纠正偏见，开源模型提供高效低成本替代方案。

Abstract: Large language models (LLMs) are transforming social-science research by
enabling scalable, precise analysis. Their adaptability raises the question of
whether knowledge acquired through fine-tuning in a few languages can transfer
to unseen languages that only appeared during pre-training. To examine this, we
fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or
multilingual data sets to classify immigration-related tweets from X/Twitter
across 13 languages, a domain characterised by polarised, culturally specific
discourse. We evaluate whether minimal language-specific fine-tuning enables
cross-lingual topic detection and whether adding targeted languages corrects
pre-training biases. Results show that LLMs fine-tuned in one or two languages
can reliably classify immigration-related content in unseen languages. However,
identifying whether a tweet expresses a pro- or anti-immigration stance
benefits from multilingual fine-tuning. Pre-training bias favours dominant
languages, but even minimal exposure to under-represented languages during
fine-tuning (as little as $9.62\times10^{-11}$ of the original pre-training
token volume) yields significant gains. These findings challenge the assumption
that cross-lingual mastery requires extensive multilingual training: limited
language coverage suffices for topic-level generalisation, and structural
biases can be corrected with lightweight interventions. By releasing
4-bit-quantised, LoRA fine-tuned models, we provide an open-source,
reproducible alternative to proprietary LLMs that delivers 35 times faster
inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,
enabling scalable, inclusive research.

</details>


### [40] [Echoes of Automation: The Increasing Use of LLMs in Newsmaking](https://arxiv.org/abs/2508.06445)
*Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee*

Main category: cs.CL

TL;DR: 研究发现，生成式AI（尤其是LLMs）在新闻内容中的使用显著增加，尤其是在地方和校园新闻中。AI常用于新闻开头，而结论多为人工撰写。AI提升了词汇丰富度和可读性，但降低了正式性。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI对新闻完整性和作者身份的潜在影响。

Method: 分析超过40,000篇新闻文章，使用三种AI文本检测工具（Binoculars、Fast-Detect GPT、GPTZero）进行句子级和语言分析。

Result: AI在新闻中的使用显著增加，尤其在地方和校园新闻中；AI提升了词汇丰富度和可读性，但降低了正式性。

Conclusion: 生成式AI改变了新闻写作风格，需关注其对新闻完整性的影响。

Abstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns
for journalistic integrity and authorship. This study examines AI-generated
content across over 40,000 news articles from major, local, and college news
media, in various media formats. Using three advanced AI-text detectors (e.g.,
Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of
GenAI use in recent years, especially in local and college news. Sentence-level
analysis reveals LLMs are often used in the introduction of news, while
conclusions usually written manually. Linguistic analysis shows GenAI boosts
word richness and readability but lowers formality, leading to more uniform
writing styles, particularly in local media.

</details>


### [41] [SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning](https://arxiv.org/abs/2508.06447)
*Lingkun Long,Rubing Yang,Yushi Huang,Desheng Hui,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: SlimInfer通过动态剪枝冗余提示令牌加速LLM推理，减少计算和内存开销，同时保持语义完整性。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理对LLM计算需求高，现有方法仍处理全部隐藏状态，效率有限。

Method: 提出SlimInfer框架，利用信息扩散现象动态剪枝中间层冗余令牌，并异步管理KV缓存。

Result: 在LLaMA3.1-8B-Instruct上实现2.53倍TTFT加速和1.88倍端到端延迟降低，性能不降。

Conclusion: SlimInfer高效加速LLM推理，适用于长上下文任务。

Abstract: Long-context inference for Large Language Models (LLMs) is heavily limited by
high computational demands. While several existing methods optimize attention
computation, they still process the full set of hidden states at each layer,
limiting overall efficiency. In this work, we propose SlimInfer, an innovative
framework that aims to accelerate inference by directly pruning less critical
prompt tokens during the forward pass. Our key insight is an information
diffusion phenomenon: As information from critical tokens propagates through
layers, it becomes distributed across the entire sequence. This diffusion
process suggests that LLMs can maintain their semantic integrity when excessive
tokens, even including these critical ones, are pruned in hidden states.
Motivated by this, SlimInfer introduces a dynamic fine-grained pruning
mechanism that accurately removes redundant tokens of hidden state at
intermediate layers. This layer-wise pruning naturally enables an asynchronous
KV cache manager that prefetches required token blocks without complex
predictors, reducing both memory usage and I/O costs. Extensive experiments
show that SlimInfer can achieve up to $\mathbf{2.53\times}$ time-to-first-token
(TTFT) speedup and $\mathbf{1.88\times}$ end-to-end latency reduction for
LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on
LongBench. Our code will be released upon acceptance.

</details>


### [42] [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471)
*GLM-4. 5 Team,:,Aohan Zeng,Xin Lv,Qinkai Zheng,Zhenyu Hou,Bin Chen,Chengxing Xie,Cunxiang Wang,Da Yin,Hao Zeng,Jiajie Zhang,Kedong Wang,Lucen Zhong,Mingdao Liu,Rui Lu,Shulin Cao,Xiaohan Zhang,Xuancheng Huang,Yao Wei,Yean Cheng,Yifan An,Yilin Niu,Yuanhao Wen,Yushi Bai,Zhengxiao Du,Zihan Wang,Zilin Zhu,Bohan Zhang,Bosi Wen,Bowen Wu,Bowen Xu,Can Huang,Casey Zhao,Changpeng Cai,Chao Yu,Chen Li,Chendi Ge,Chenghua Huang,Chenhui Zhang,Chenxi Xu,Chenzheng Zhu,Chuang Li,Congfeng Yin,Daoyan Lin,Dayong Yang,Dazhi Jiang,Ding Ai,Erle Zhu,Fei Wang,Gengzheng Pan,Guo Wang,Hailong Sun,Haitao Li,Haiyang Li,Haiyi Hu,Hanyu Zhang,Hao Peng,Hao Tai,Haoke Zhang,Haoran Wang,Haoyu Yang,He Liu,He Zhao,Hongwei Liu,Hongxi Yan,Huan Liu,Huilong Chen,Ji Li,Jiajing Zhao,Jiamin Ren,Jian Jiao,Jiani Zhao,Jianyang Yan,Jiaqi Wang,Jiayi Gui,Jiayue Zhao,Jie Liu,Jijie Li,Jing Li,Jing Lu,Jingsen Wang,Jingwei Yuan,Jingxuan Li,Jingzhao Du,Jinhua Du,Jinxin Liu,Junkai Zhi,Junli Gao,Ke Wang,Lekang Yang,Liang Xu,Lin Fan,Lindong Wu,Lintao Ding,Lu Wang,Man Zhang,Minghao Li,Minghuan Xu,Mingming Zhao,Mingshu Zhai,Pengfan Du,Qian Dong,Shangde Lei,Shangqing Tu,Shangtong Yang,Shaoyou Lu,Shijie Li,Shuang Li,Shuang-Li,Shuxun Yang,Sibo Yi,Tianshu Yu,Wei Tian,Weihan Wang,Wenbo Yu,Weng Lam Tam,Wenjie Liang,Wentao Liu,Xiao Wang,Xiaohan Jia,Xiaotao Gu,Xiaoying Ling,Xin Wang,Xing Fan,Xingru Pan,Xinyuan Zhang,Xinze Zhang,Xiuqing Fu,Xunkai Zhang,Yabo Xu,Yandong Wu,Yida Lu,Yidong Wang,Yilin Zhou,Yiming Pan,Ying Zhang,Yingli Wang,Yingru Li,Yinpei Su,Yipeng Geng,Yitong Zhu,Yongkun Yang,Yuhang Li,Yuhao Wu,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yuxuan Zhang,Zezhen Liu,Zhen Yang,Zhengda Zhou,Zhongpei Qiao,Zhuoer Feng,Zhuorui Liu,Zichen Zhang,Zihan Wang,Zijun Yao,Zikang Wang,Ziqiang Liu,Ziwei Chai,Zixuan Li,Zuodong Zhao,Wenguang Chen,Jidong Zhai,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.CL

TL;DR: GLM-4.5是一个开源的混合专家（MoE）大语言模型，总参数量355B，激活参数量32B，支持混合推理模式。通过多阶段训练和强化学习，在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 推动推理和代理AI系统的研究，提供高效且性能强大的开源模型。

Method: 采用混合专家架构和多阶段训练，结合强化学习优化模型性能。

Result: 在TAU-Bench、AIME 24和SWE-bench Verified等任务上表现优异，参数量少于竞争对手但排名靠前。

Conclusion: GLM-4.5及其紧凑版本GLM-4.5-Air为推理和代理AI系统提供了高效解决方案，开源以促进研究。

Abstract: We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language
model with 355B total parameters and 32B activated parameters, featuring a
hybrid reasoning method that supports both thinking and direct response modes.
Through multi-stage training on 23T tokens and comprehensive post-training with
expert model iteration and reinforcement learning, GLM-4.5 achieves strong
performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on
TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer
parameters than several competitors, GLM-4.5 ranks 3rd overall among all
evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B
parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance
research in reasoning and agentic AI systems. Code, models, and more
information are available at https://github.com/zai-org/GLM-4.5.

</details>


### [43] [HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning](https://arxiv.org/abs/2508.06475)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 论文提出HapticLLaMA模型，用于将触觉信号（如振动）转化为自然语言描述，填补了多模态研究中触觉信号的空白。


<details>
  <summary>Details</summary>
Motivation: 触觉信号在多模态研究中未被充分探索，而其在虚拟现实、无障碍和康复应用中具有潜力。

Method: 提出HapticLLaMA模型，结合频率和EnCodec两种触觉分词器，通过LLaMA架构和RLHF进行两阶段训练。

Result: 模型在METEOR和BLEU-4评分上表现优异，61%的生成描述获人类评分超过3.5（7分制），RLHF提升10%评分分布。

Conclusion: HapticLLaMA展示了大型语言模型处理感官数据的潜力，为触觉信号的自然语言描述提供了有效解决方案。

Abstract: Haptic captioning is the task of generating natural language descriptions
from haptic signals, such as vibrations, for use in virtual reality,
accessibility, and rehabilitation applications. While previous multimodal
research has focused primarily on vision and audio, haptic signals for the
sense of touch remain underexplored. To address this gap, we formalize the
haptic captioning task and propose HapticLLaMA, a multimodal sensory language
model that interprets vibration signals into descriptions in a given sensory,
emotional, or associative category. We investigate two types of haptic
tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that
convert haptic signals into sequences of discrete units, enabling their
integration with the LLaMA model. HapticLLaMA is trained in two stages: (1)
supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,
and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We
assess HapticLLaMA's captioning performance using both automated n-gram metrics
and human evaluation. HapticLLaMA demonstrates strong capability in
interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a
BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated
captions received human ratings above 3.5 on a 7-point scale, with RLHF
yielding a 10% improvement in the overall rating distribution, indicating
stronger alignment with human haptic perception. These findings highlight the
potential of large language models to process and adapt to sensory data.

</details>


### [44] [Post-training for Efficient Communication via Convention Formation](https://arxiv.org/abs/2508.06482)
*Yilun Hua,Evan Wang,Yoav Artzi*

Main category: cs.CL

TL;DR: 论文提出了一种后训练方法，通过微调提升大语言模型在多轮交互中的适应性，使其能像人类一样形成临时约定。


<details>
  <summary>Details</summary>
Motivation: 人类在多轮交互中能高效适应语言并形成临时约定，而现有大语言模型缺乏这种能力。

Method: 通过启发式识别约定形成的演示数据，进行针对性微调。

Result: 后训练模型在两个新基准测试中表现出显著提升的约定形成能力。

Conclusion: 该方法有效提升了语言模型在多轮交互中的适应性。

Abstract: Humans communicate with increasing efficiency in multi-turn interactions, by
adapting their language and forming ad-hoc conventions. In contrast, prior work
shows that LLMs do not naturally show this behavior. We develop a post-training
process to develop this ability through targeted fine-tuning on heuristically
identified demonstrations of convention formation. We evaluate with two new
benchmarks focused on this capability. First, we design a focused,
cognitively-motivated interaction benchmark that consistently elicits strong
convention formation trends in humans. Second, we create a new
document-grounded reference completion task that reflects in-the-wild
convention formation behavior. Our studies show significantly improved
convention formation abilities in post-trained LLMs across the two evaluation
methods.

</details>


### [45] [Indian Legal NLP Benchmarks : A Survey](https://arxiv.org/abs/2107.06056)
*Prathamesh Kalamkar,Janani Venugopalan Ph. D.,Vivek Raghavan Ph. D*

Main category: cs.CL

TL;DR: 论文呼吁为印度法律文本创建专门的NLP基准，以推动AI在法律领域的应用。


<details>
  <summary>Details</summary>
Motivation: 法律文本与普通英语文本差异显著，需要针对印度法律系统设计专门的NLP基准，以促进该领域的技术创新。

Method: 回顾现有研究并提出创建新基准的思路。

Result: 提出为印度法律文本设计挑战性NLP任务的必要性。

Conclusion: 创建专门基准将推动AI在法律领域的应用，并惠及AI社区和法律界。

Abstract: Availability of challenging benchmarks is the key to advancement of AI in a
specific field.Since Legal Text is significantly different than normal English
text, there is a need to create separate Natural Language Processing benchmarks
for Indian Legal Text which are challenging and focus on tasks specific to
Legal Systems. This will spur innovation in applications of Natural language
Processing for Indian Legal Text and will benefit AI community and Legal
fraternity. We review the existing work in this area and propose ideas to
create new benchmarks for Indian Legal Natural Language Processing.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [46] [Automated Visualization Makeovers with LLMs](https://arxiv.org/abs/2508.05637)
*Siddharth Gangwar,David A. Selby,Sebastian J. Vollmer*

Main category: cs.HC

TL;DR: 论文探讨了如何利用多模态大型语言模型（LLMs）对数据可视化进行改进，通过提示工程生成建设性批评，帮助用户提升图表质量。


<details>
  <summary>Details</summary>
Motivation: 数据可视化是艺术与科学的结合，但数据科学课程中通常未教授相关技巧。社区通过可视化改造练习交流反馈，本文探索LLMs是否能模拟这一任务。

Method: 利用预训练模型进行提示工程，结合用户指定的指南和LLMs的潜在知识，生成改进建议。重点在于教育用户如何优化现有可视化，而非从原始数据生成脚本。

Result: 通过定量评估，测量了LLM对不同图表类型中问题的敏感性。工具以简单自托管应用形式提供，配有可访问的Web界面。

Conclusion: LLMs能够有效辅助数据可视化改进，提供了一种半自动化的教育工具。

Abstract: Making a good graphic that accurately and efficiently conveys the desired
message to the audience is both an art and a science, typically not taught in
the data science curriculum. Visualisation makeovers are exercises where the
community exchange feedback to improve charts and data visualizations. Can
multi-modal large language models (LLMs) emulate this task? Given a plot in the
form of an image file, or the code used to generate it, an LLM, primed with a
list of visualization best practices, is employed to semi-automatically
generate constructive criticism to produce a better plot. Our system is centred
around prompt engineering of a pre-trained model, relying on a combination of
userspecified guidelines and any latent knowledge of data visualization
practices that might lie within an LLMs training corpus. Unlike other works,
the focus is not on generating valid visualization scripts from raw data or
prompts, but on educating the user how to improve their existing data
visualizations according to an interpretation of best practices. A quantitative
evaluation is performed to measure the sensitivity of the LLM agent to various
plotting issues across different chart types. We make the tool available as a
simple self-hosted applet with an accessible Web interface.

</details>


### [47] [A Humanoid Social Robot as a Teaching Assistant in the Classroom](https://arxiv.org/abs/2508.05646)
*Thomas Sievers*

Main category: cs.HC

TL;DR: 研究探讨了社交机器人Pepper结合ChatGPT在高中课堂中的应用，学生对其接受度和实用性持积极态度。


<details>
  <summary>Details</summary>
Motivation: 教育系统需要创新技术支持，但社交机器人在学校的应用较少，CRI可为教师提供帮助并增强学习环境。

Method: 使用Pepper机器人连接ChatGPT，在高中课堂中教授新内容，测试技术可行性并调查学生接受度。

Result: 所有学生认为机器人呈现的学习材料合适或部分合适，其使用有意义。

Conclusion: 社交机器人在教育中具有潜力，学生对其接受度高，未来可进一步探索其应用。

Abstract: Although innovation and the support of new technologies are much needed to
ease the burden on the education system, social robots in schools to help
teachers with educational tasks are rare. Child-Robot Interaction (CRI) could
support teachers and add an embodied social component to modern multi-modal and
multi-sensory learning environments already in use. The social robot Pepper,
connected to the Large Language Model (LLM) ChatGPT, was used in a high school
classroom to teach new learning content to groups of students. I tested the
technical possibilities with the robot on site and asked the students about
their acceptance and perceived usefulness of teaching with the help of a social
robot. All participants felt that the robot's presentation of the learning
material was appropriate or at least partially appropriate and that its use
made sense.

</details>


### [48] [Modeling Interactive Narrative Systems: A Formal Approach](https://arxiv.org/abs/2508.05653)
*Jules Clerc,Domitile Lourdeaux,Mohamed Sallak,Johann Barbier,Marc Ravaine*

Main category: cs.HC

TL;DR: 本文提出了一种用于交互式叙事系统（INS）的形式化表示框架，旨在解决研究分散和系统表示多样的问题。


<details>
  <summary>Details</summary>
Motivation: 交互式叙事系统（INS）通过让用户主动塑造故事，改变了传统被动叙事方式，但研究分散且系统表示多样，亟需统一框架。

Method: 提出一个形式化表示框架，提供一致的词汇和建模结构，便于分析、描述和比较INS特性。

Result: 通过“小红帽”场景的实验验证，证明了该形式化框架的有效性及其对INS评估的改进作用。

Conclusion: 该框架旨在促进INS研究社区的合作与一致性，为系统形式化表示提供方法论。

Abstract: Interactive Narrative Systems (INS) have revolutionized digital experiences
by empowering users to actively shape their stories, diverging from traditional
passive storytelling. However, the field faces challenges due to fragmented
research efforts and diverse system representations. This paper introduces a
formal representation framework for INS, inspired by diverse approaches from
the state of the art. By providing a consistent vocabulary and modeling
structure, the framework facilitates the analysis, the description and
comparison of INS properties. Experimental validations on the "Little Red
Riding Hood" scenario highlight the usefulness of the proposed formalism and
its impact on improving the evaluation of INS. This work aims to foster
collaboration and coherence within the INS research community by proposing a
methodology for formally representing these systems.

</details>


### [49] [Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction](https://arxiv.org/abs/2508.05913)
*Stefan Pasch,Min Chul Cha*

Main category: cs.HC

TL;DR: 研究通过分析10万条AI产品用户评论，发现伦理AI的七个维度与用户满意度正相关，且非技术用户和终端应用用户更关注伦理问题。


<details>
  <summary>Details</summary>
Motivation: 探讨伦理AI原则是否被用户认可、重视及影响其满意度。

Method: 使用基于Transformer的语言模型分析G2平台上的用户评论，测量七个伦理维度的情感倾向。

Result: 所有伦理维度均与用户满意度正相关，非技术用户和终端应用用户对伦理问题的关注更强。

Conclusion: 伦理AI设计需考虑用户角色和产品类型的差异，以提升用户满意度。

Abstract: As AI systems become increasingly embedded in organizational workflows and
consumer applications, ethical principles such as fairness, transparency, and
robustness have been widely endorsed in policy and industry guidelines.
However, there is still scarce empirical evidence on whether these principles
are recognized, valued, or impactful from the perspective of users. This study
investigates the link between ethical AI and user satisfaction by analyzing
over 100,000 user reviews of AI products from G2. Using transformer-based
language models, we measure sentiment across seven ethical dimensions defined
by the EU Ethics Guidelines for Trustworthy AI. Our findings show that all
seven dimensions are positively associated with user satisfaction. Yet, this
relationship varies systematically across user and product types. Technical
users and reviewers of AI development platforms more frequently discuss
system-level concerns (e.g., transparency, data governance), while
non-technical users and reviewers of end-user applications emphasize
human-centric dimensions (e.g., human agency, societal well-being). Moreover,
the association between ethical AI and user satisfaction is significantly
stronger for non-technical users and end-user applications across all
dimensions. Our results highlight the importance of ethical AI design from
users' perspectives and underscore the need to account for contextual
differences across user roles and product types.

</details>


### [50] [REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition](https://arxiv.org/abs/2508.05933)
*Xueyuan Xu,Wenjia Dong,Fulin Wei,Li Zhuo*

Main category: cs.HC

TL;DR: 提出了一种基于自适应正交非负矩阵分解的EEG特征选择方法，用于解决多维度情绪识别中标签缺失和特征冗余的问题。


<details>
  <summary>Details</summary>
Motivation: 多类型EEG特征虽能提供多层次情绪分析，但高维度和样本稀缺导致分类器过拟合和实时性能问题，且实际应用中标签缺失和情绪感知模糊性进一步增加了挑战。

Method: 采用自适应正交非负矩阵分解重构情绪标签空间，结合最小二乘回归和图流形学习正则化，实现缺失信息下的特征选择。

Result: 在DREAMER、DEAP和HDED数据集上，该方法优于13种先进特征选择方法，表现出更强的鲁棒性。

Conclusion: 该方法有效解决了多维度情绪识别中的标签缺失和特征冗余问题，提升了EEG情感识别的鲁棒性。

Abstract: The affective brain-computer interface is a crucial technology for affective
interaction and emotional intelligence, emerging as a significant area of
research in the human-computer interaction. Compared to single-type features,
multi-type EEG features provide a multi-level representation for analyzing
multi-dimensional emotions. However, the high dimensionality of multi-type EEG
features, combined with the relatively small number of high-quality EEG
samples, poses challenges such as classifier overfitting and suboptimal
real-time performance in multi-dimensional emotion recognition. Moreover,
practical applications of affective brain-computer interface frequently
encounters partial absence of multi-dimensional emotional labels due to the
open nature of the acquisition environment, and ambiguity and variability in
individual emotion perception. To address these challenges, this study proposes
a novel EEG feature selection method for missing multi-dimensional emotion
recognition. The method leverages adaptive orthogonal non-negative matrix
factorization to reconstruct the multi-dimensional emotional label space
through second-order and higher-order correlations, which could reduce the
negative impact of missing values and outliers on label reconstruction.
Simultaneously, it employs least squares regression with graph-based manifold
learning regularization and global feature redundancy minimization
regularization to enable EEG feature subset selection despite missing
information, ultimately achieving robust EEG-based multi-dimensional emotion
recognition. Simulation experiments on three widely used multi-dimensional
emotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method
outperforms thirteen advanced feature selection methods in terms of robustness
for EEG emotional feature selection.

</details>


### [51] [ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection](https://arxiv.org/abs/2508.05934)
*Xueyuan Xu,Tianze Yu,Wenjia Dong,Fulin Wei,Li Zhuo*

Main category: cs.HC

TL;DR: 提出了一种名为ASLSL的新方法，用于处理不完整多模态生理信号的特征选择问题，通过共享潜在结构学习减少缺失信息的影响。


<details>
  <summary>Details</summary>
Motivation: 多模态生理信号情感识别中，高维特征常包含无关、冗余和噪声信息，导致过拟合和性能下降。现有方法假设数据完整，但实际数据常不完整。

Method: 采用自适应共享潜在结构学习（ASLSL），探索不完整多模态信号和情感标签的共享潜在空间，挖掘共识信息。

Result: 在DEAP和DREAMER数据集上，ASLSL优于17种特征选择方法。

Conclusion: ASLSL有效解决了不完整多模态生理信号的特征选择问题，提升了情感识别性能。

Abstract: Recently, multi-modal physiological signals based emotion recognition has
garnered increasing attention in the field of brain-computer interfaces.
Nevertheness, the associated multi-modal physiological features are often
high-dimensional and inevitably include irrelevant, redundant, and noisy
representation, which can easily lead to overfitting, poor performance, and
high computational complexity in emotion classifiers. Feature selection has
been widely applied to address these challenges. However, previous studies
generally assumed that multi-modal physiological data are complete, whereas in
reality, the data are often incomplete due to the openness of the acquisition
and operational environment. For example, a part of samples are available in
several modalities but not in others. To address this issue, we propose a novel
method for incomplete multi-modal physiological signal feature selection called
adaptive shared latent structure learning (ASLSL). Based on the property that
similar features share similar emotional labels, ASLSL employs adaptive shared
latent structure learning to explore a common latent space shared for
incomplete multi-modal physiological signals and multi-dimensional emotional
labels, thereby mitigating the impact of missing information and mining
consensus information. Two most popular multi-modal physiological emotion
datasets (DEAP and DREAMER) with multi-dimensional emotional labels were
utilized to compare the performance between compare ASLSL and seventeen feature
selection methods. Comprehensive experimental results on these datasets
demonstrate the effectiveness of ASLSL.

</details>


### [52] [It's a Complete Haystack: Understanding Dependency Management Needs in Computer-Aided Design](https://arxiv.org/abs/2508.05940)
*Kathy Cheng,Alison Olechowski,Shurui Zhou*

Main category: cs.HC

TL;DR: 硬件设计团队面临CAD依赖管理的挑战，研究通过分析论坛讨论和设计师访谈，提出改进协作流程的设计目标和功能。


<details>
  <summary>Details</summary>
Motivation: 硬件设计师在管理3D CAD模型依赖时缺乏意识，影响团队协作效率，需解决此问题。

Method: 通过分析100个在线论坛讨论和10位设计师的半结构化访谈，进行主题分析。

Result: 识别出9个与CAD依赖相关的关键挑战，提出改进协作流程的设计目标和功能。

Conclusion: 研究为提升硬件设计师对依赖的意识和管理提供了解决方案，旨在优化协作工作流程。

Abstract: In today's landscape, hardware development teams face increasing demands for
better quality products, greater innovation, and shorter manufacturing lead
times. Despite the need for more efficient and effective processes, hardware
designers continue to struggle with a lack of awareness of design changes and
other collaborators' actions, a persistent issue in decades of CSCW research.
One significant and unaddressed challenge is understanding and managing
dependencies between 3D CAD (computer-aided design) models, especially when
products can contain thousands of interconnected components. In this two-phase
formative study, we explore designers' pain points of CAD dependency management
through a thematic analysis of 100 online forum discussions and semi-structured
interviews with 10 designers. We identify nine key challenges related to the
traceability, navigation, and consistency of CAD dependencies, that harm the
effective coordination of hardware development teams. To address these
challenges, we propose design goals and necessary features to enhance hardware
designers' awareness and management of dependencies, ultimately with the goal
of improving collaborative workflows.

</details>


### [53] [Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning](https://arxiv.org/abs/2508.06000)
*Wei Xiang,Ziyue Lei,Haoyuan Che,Fangyuan Ye,Xueting Wu,Lingyun Sun*

Main category: cs.HC

TL;DR: 论文探讨了如何通过LLM驱动的动觉辅助提升操作技能学习效果，开发了结合LLM与EMS的工具FlightAxis，显著提高了用户接受度和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练助手主要提供文本反馈，忽视了动觉模态的重要性，限制了操作技能学习的效果。

Method: 提出'Align-Analyze-Adjust'策略，开发FlightAxis工具，结合LLM与EMS指导模拟飞行任务中的前臂动作。

Result: 用户对LLM驱动的身体控制接受度高，任务完成时间显著减少，动觉辅助增强了操作缺陷意识和训练参与度。

Conclusion: 研究表明动觉LLM训练在操作技能学习中具有潜力，未来可进一步探索其应用。

Abstract: Operational skill learning, inherently physical and reliant on hands-on
practice and kinesthetic feedback, has yet to be effectively replicated in
large language model (LLM)-supported training. Current LLM training assistants
primarily generate customized textual feedback, neglecting the crucial
kinesthetic modality. This gap derives from the textual and uncertain nature of
LLMs, compounded by concerns on user acceptance of LLM driven body control. To
bridge this gap and realize the potential of collaborative human-LLM action,
this work explores human experience of LLM driven kinesthetic assistance.
Specifically, we introduced an "Align-Analyze-Adjust" strategy and developed
FlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS)
for flight skill acquisition, a representative operational skill domain.
FlightAxis learns flight skills from manuals and guides forearm movements
during simulated flight tasks. Our results demonstrate high user acceptance of
LLM-mediated body control and significantly reduced task completion times.
Crucially, trainees reported that this kinesthetic assistance enhanced their
awareness of operation flaws and fostered increased engagement in the training
process, rather than relieving perceived load. This work demonstrated the
potential of kinesthetic LLM training in operational skill acquisition.

</details>


### [54] [RAGTrace: Understanding and Refining Retrieval-Generation Dynamics in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.06056)
*Sizhe Cheng,Jiaping Li,Huanchen Wang,Yuxin Ma*

Main category: cs.HC

TL;DR: RAGTrace是一个交互式评估系统，用于分析RAG工作流中的检索与生成动态，支持多级分析，揭示检索与生成的关系。


<details>
  <summary>Details</summary>
Motivation: RAG系统在提升LLMs方面具有潜力，但其内部知识整合和检索-生成交互过程不透明，亟需透明化评估工具。

Method: 通过文献综述和专家访谈，开发了RAGTrace系统，支持从宏观性能到微观检索相关性、生成保真度及跨组件交互的全面分析。

Result: RAGTrace通过案例研究和专家评估验证了其有效性，能够追踪知识源并识别潜在失败点。

Conclusion: RAGTrace为RAG工作流提供了透明化评估方法，有助于优化检索过程并提升生成质量。

Abstract: Retrieval-Augmented Generation (RAG) systems have emerged as a promising
solution to enhance large language models (LLMs) by integrating external
knowledge retrieval with generative capabilities. While significant
advancements have been made in improving retrieval accuracy and response
quality, a critical challenge remains that the internal knowledge integration
and retrieval-generation interactions in RAG workflows are largely opaque. This
paper introduces RAGTrace, an interactive evaluation system designed to analyze
retrieval and generation dynamics in RAG-based workflows. Informed by a
comprehensive literature review and expert interviews, the system supports a
multi-level analysis approach, ranging from high-level performance evaluation
to fine-grained examination of retrieval relevance, generation fidelity, and
cross-component interactions. Unlike conventional evaluation practices that
focus on isolated retrieval or generation quality assessments, RAGTrace enables
an integrated exploration of retrieval-generation relationships, allowing users
to trace knowledge sources and identify potential failure cases. The system's
workflow allows users to build, evaluate, and iterate on retrieval processes
tailored to their specific domains of interest. The effectiveness of the system
is demonstrated through case studies and expert evaluations on real-world RAG
applications.

</details>


### [55] [ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation](https://arxiv.org/abs/2508.06065)
*Daniel Lee,Nikhil Sharma,Donghoon Shin,DaEun Choi,Harsh Sharma,Jeonghwan Kim,Heng Ji*

Main category: cs.HC

TL;DR: ThematicPlane系统通过交互式主题设计平面帮助用户导航和操作高级语义概念，弥合创意意图与系统控制之间的差距。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使图像创作更易用，但非专家用户难以精确表达创意意图，现有工具限制探索灵活性。

Method: 引入ThematicPlane系统，支持用户通过交互界面操作语义概念（如情绪、风格或叙事基调）。

Result: 探索性研究（N=6）显示用户能进行发散和收敛创作，但主题映射需更明确的控制。

Conclusion: ThematicPlane支持迭代式创作流程，为生成设计工具提供直观的语义驱动交互方向。

Abstract: Generative AI has made image creation more accessible, yet aligning outputs
with nuanced creative intent remains challenging, particularly for non-experts.
Existing tools often require users to externalize ideas through prompts or
references, limiting fluid exploration. We introduce ThematicPlane, a system
that enables users to navigate and manipulate high-level semantic concepts
(e.g., mood, style, or narrative tone) within an interactive thematic design
plane. This interface bridges the gap between tacit creative intent and system
control. In our exploratory study (N=6), participants engaged in divergent and
convergent creative modes, often embracing unexpected results as inspiration or
iteration cues. While they grounded their exploration in familiar themes,
differing expectations of how themes mapped to outputs revealed a need for more
explainable controls. Overall, ThematicPlane fosters expressive, iterative
workflows and highlights new directions for intuitive, semantics-driven
interaction in generative design tools.

</details>


### [56] [A Multimodal Framework for Understanding Collaborative Design Processes](https://arxiv.org/abs/2508.06117)
*Maurice Koch,Nelusa Pathmanathan,Daniel Weiskopf,Kuno Kurzhals*

Main category: cs.HC

TL;DR: 提出了一种模块化框架reCAPit，用于多模态数据采集、AI提取和可视化分析，以解决协作设计研讨会中数据整合的挑战。


<details>
  <summary>Details</summary>
Motivation: 协作设计研讨会中，数据来源多样且异构，传统方法难以有效整合和分析多模态数据。

Method: 开发了reCAPit系统，结合视频、音频、笔记等多模态数据，通过AI提取和交互式可视化分析。

Result: 在六个研讨会中验证了框架的有效性，并通过案例研究展示了其应用。

Conclusion: 该研究扩展了协作设计研讨会的方法学，支持多模态数据采集、AI分析和结果透明传播。

Abstract: An essential task in analyzing collaborative design processes, such as those
that are part of workshops in design studies, is identifying design outcomes
and understanding how the collaboration between participants formed the results
and led to decision-making. However, findings are typically restricted to a
consolidated textual form based on notes from interviews or observations. A
challenge arises from integrating different sources of observations, leading to
large amounts and heterogeneity of collected data. To address this challenge we
propose a practical, modular, and adaptable framework of workshop setup,
multimodal data acquisition, AI-based artifact extraction, and visual analysis.
Our interactive visual analysis system, reCAPit, allows the flexible
combination of different modalities, including video, audio, notes, or gaze, to
analyze and communicate important workshop findings. A multimodal streamgraph
displays activity and attention in the working area, temporally aligned topic
cards summarize participants' discussions, and drill-down techniques allow
inspecting raw data of included sources. As part of our research, we conducted
six workshops across different themes ranging from social science research on
urban planning to a design study on band-practice visualization. The latter two
are examined in detail and described as case studies. Further, we present
considerations for planning workshops and challenges that we derive from our
own experience and the interviews we conducted with workshop experts. Our
research extends existing methodology of collaborative design workshops by
promoting data-rich acquisition of multimodal observations, combined AI-based
extraction and interactive visual analysis, and transparent dissemination of
results.

</details>


### [57] [Automatic Semantic Alignment of Flow Pattern Representations for Exploration with Large Language Models](https://arxiv.org/abs/2508.06300)
*Weihan Zhang,Jun Tao*

Main category: cs.HC

TL;DR: 论文提出了一种基于自然语言交互的流场可视化框架，通过将流模式表示与大型语言模型（LLM）语义空间对齐，实现无需手动标注的智能流场探索。


<details>
  <summary>Details</summary>
Motivation: 传统流场可视化界面依赖专业图形表示和交互方式，学习成本高；自然语言交互更直观，但机器识别科学概念并提取流场结构具有挑战性。

Method: 使用去噪自编码器编码流线段，通过投影层将生成的流模式表示映射到LLM嵌入空间，利用注意力机制实现文本嵌入与流表示的语义匹配。

Result: 开发了交互式界面，支持用户通过自然语言查询和可视化流场结构，案例研究验证了框架的有效性。

Conclusion: 该框架实现了直观且智能的流场探索，提升了流场可视化的可访问性。

Abstract: Explorative flow visualization allows domain experts to analyze complex flow
structures by interactively investigating flow patterns. However, traditional
visual interfaces often rely on specialized graphical representations and
interactions, which require additional effort to learn and use. Natural
language interaction offers a more intuitive alternative, but teaching machines
to recognize diverse scientific concepts and extract corresponding structures
from flow data poses a significant challenge. In this paper, we introduce an
automated framework that aligns flow pattern representations with the semantic
space of large language models (LLMs), eliminating the need for manual
labeling. Our approach encodes streamline segments using a denoising
autoencoder and maps the generated flow pattern representations to LLM
embeddings via a projector layer. This alignment empowers semantic matching
between textual embeddings and flow representations through an attention
mechanism, enabling the extraction of corresponding flow patterns based on
textual descriptions. To enhance accessibility, we develop an interactive
interface that allows users to query and visualize flow structures using
natural language. Through case studies, we demonstrate the effectiveness of our
framework in enabling intuitive and intelligent flow exploration.

</details>


### [58] [Emoji Reactions on Telegram Often Reflect Social Approval Over Emotional Resonance](https://arxiv.org/abs/2508.06349)
*Serena Tardelli,Lorenzo Alvisi,Lorenzo Cima,Stefano Cresci,Maurizio Tesconi*

Main category: cs.HC

TL;DR: 研究发现Telegram上的表情符号反应更多体现社交认可而非情感共鸣，正面反应占主导，与消息情感不一致。


<details>
  <summary>Details</summary>
Motivation: 探索表情符号反应在社交动态中的功能，而非仅作为情感指标。

Method: 收集65万条Telegram消息，标注情感、修辞策略等，分析表情反应的情感。

Result: 表情反应与消息情感不匹配，正面反应普遍，可能反映社交认可。

Conclusion: 表情符号反应不宜直接作为情感共鸣的代理，需考虑社交动态。

Abstract: Emoji reactions are a frequently used feature of messaging platforms. Prior
work mainly interpreted emojis as indicators of emotional resonance or user
sentiment. However, emoji reactions may instead reflect broader social
dynamics. Here, we investigate the communicative function of emoji reactions on
Telegram by analyzing the relationship between the emotional and rhetorical
content of messages and the emoji reactions they receive. We collect and
analyze over 650k Telegram messages that received at least one emoji reaction.
We annotate each message with sentiment, emotion, persuasion strategy, and
speech act labels, and infer the sentiment and emotion of emoji reactions using
both lexicons and large languages. We find a systematic mismatch between
message sentiment and reaction sentiment, with positive reactions dominating
even when the message is neutral or negative. We show that this pattern remains
consistent across rhetorical strategies and emotional tones, suggesting that
emoji reactions may signal a degree of social approval rather than reflecting
emotional resonance. Finally, we shed light on the communicative strategies
that predict greater emoji engagement. These findings have methodological
implications for sentiment analysis, as interpreting emoji reactions as direct
proxies for emotional response may be misleading.

</details>


### [59] [Zombitron: towards a toolbox for repurposing obsolete smartphones into new interactive systems](https://arxiv.org/abs/2508.06354)
*Clara Rigaud*

Main category: cs.HC

TL;DR: 研究探讨如何利用废弃智能手机和平板电脑构建新的交互系统，以音乐控制器为例，记录从诊断到创建自主电子对象的过程，并提供软硬件见解，目标是开发开源工具包。


<details>
  <summary>Details</summary>
Motivation: 探索废弃设备的再利用潜力，推动可持续计算和交互系统设计。

Method: 通过案例研究（音乐控制器），记录设计过程、障碍和解决方案，并与专业音乐家讨论。

Result: 提出了基于废弃设备的交互系统设计见解，并探讨了基于网页的高层次方法如何促进可持续计算。

Conclusion: 废弃设备再利用具有潜力，开源工具包和网页方法可推动可持续交互系统的发展。

Abstract: This article explores the possibilities of reusing obsolete smartphones and
tablets to build new interactive systems. Taking the case of a musical
instrument, I present my research into the design of a controller made from
various of these obsolete smartphones. From the diagnostic stage to the
creation of a new autonomous electronic object, I document the process, the
barriers and the levers encountered. Based on these explorations and
discussions with two professional musicians, I provide several insights into
the software and hardware aspects, with a view to continuing this work, towards
the creation of an open-source toolkit enabling anyone to build new interactive
systems with old devices. I discuss the implication of how a high-level
web-based approach could allow designers to enter the black box and foster
permacomputing using smartphones.

</details>


### [60] [Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data](https://arxiv.org/abs/2508.06484)
*Yuvraj Virk,Dongyu Liu*

Main category: cs.HC

TL;DR: 非技术终端用户依赖AI生成代码执行技术任务，但难以识别模型错误，尤其在特定领域场景中。研究发现，即使提示用户注意错误，他们仍难以发现关键问题。


<details>
  <summary>Details</summary>
Motivation: 评估非技术用户（如市场营销和销售专业人员）是否能有效识别AI生成代码中的错误，尤其是在实际应用中。

Method: 通过调查和实验，展示AI生成的代码解释，并提示用户识别错误。随后改进展示形式（分步和提供替代方案）以支持评估。

Result: 用户普遍难以发现关键错误，即使改进展示形式后效果有限。

Conclusion: 非技术用户无法可靠验证AI生成的数据分析，需改进设计以减少错误决策风险。

Abstract: Non-technical end-users increasingly rely on AI code generation to perform
technical tasks like data analysis. However, large language models (LLMs)
remain unreliable, and it is unclear whether end-users can effectively identify
model errors $\unicode{x2014}$ especially in realistic and domain-specific
scenarios. We surveyed marketing and sales professionals to assess their
ability to critically evaluate LLM-generated analyses of marketing data.
Participants were shown natural language explanations of the AI's code,
repeatedly informed the AI often makes mistakes, and explicitly prompted to
identify them. Yet, participants frequently failed to detect critical flaws
that could compromise decision-making, many of which required no technical
knowledge to recognize. To investigate why, we reformatted AI responses into
clearly delineated steps and provided alternative approaches for each decision
to support critical evaluation. While these changes had a positive effect,
participants often struggled to reason through the AI's steps and alternatives.
Our findings suggest that business professionals cannot reliably verify
AI-generated data analyses on their own and explore reasons why to inform
future designs. As non-programmers adopt code-generating AI for technical
tasks, unreliable AI and insufficient human oversight poses risks of unsafe or
low-quality decisions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [61] [Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty](https://arxiv.org/abs/2508.05659)
*Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos*

Main category: cs.LG

TL;DR: 提出了一种将因果循环图（CLD）转换为探索性系统动力学模型（SDM）的方法Diagrams-to-Dynamics（D2D），以支持动态分析和干预策略。


<details>
  <summary>Details</summary>
Motivation: 因果循环图（CLD）作为静态定性工具，无法支持动态分析，且现有定量分析方法易导致错误推断。

Method: 通过用户简单标注变量类型，利用CLD中的结构信息（链接存在性和极性）生成SDM，模拟干预并探索潜在杠杆点。

Result: D2D能区分高、低优先级杠杆点，与数据驱动模型一致性优于网络中心性分析，并提供不确定性估计。

Conclusion: D2D方法通过开源工具实现，降低了动态建模门槛，未来验证将扩展其应用范围。

Abstract: Causal loop diagrams (CLDs) are widely used in health and environmental
research to represent hypothesized causal structures underlying complex
problems. However, as qualitative and static representations, CLDs are limited
in their ability to support dynamic analysis and inform intervention
strategies. Additionally, quantitative CLD analysis methods like network
centrality analysis often lead to false inference. We propose
Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory
system dynamics models (SDMs) in the absence of empirical data. With minimal
user input - following a protocol to label variables as stocks,
flows/auxiliaries, or constants - D2D leverages the structural information
already encoded in CLDs, namely, link existence and polarity, to simulate
hypothetical interventions and explore potential leverage points under
uncertainty. Results suggest that D2D helps distinguish between high- and
low-ranked leverage points. We compare D2D to a data-driven SDM constructed
from the same CLD and variable labeling. D2D showed greater consistency with
the data-driven model than network centrality analysis, while providing
uncertainty estimates and guidance for future data collection. The method is
implemented in an open-source Python package and a web-based application to
support further testing and lower the barrier to dynamic modeling for
researchers working with CLDs. We expect additional validation will further
establish the approach's utility across a broad range of cases and domains.

</details>


### [62] [A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics](https://arxiv.org/abs/2508.05724)
*Massimiliano Romiti*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的加权知识图谱框架，用于表示和分析物理定律，通过图注意力网络（GAT）实现了高效的链接预测，并发现了物理学中的关键概念和潜在跨领域关系。


<details>
  <summary>Details</summary>
Motivation: 解决物理方程表示中的语义模糊问题，并通过知识图谱揭示物理学中的潜在结构和跨领域联系。

Method: 构建了包含400个高级物理方程的数据库，开发了加权知识图谱表示，并训练GAT进行链接预测。

Result: GAT在链接预测中表现出色（AUC: 0.9742），显著优于基线方法，并揭示了物理学中的关键概念和潜在跨领域关系。

Conclusion: 该框架不仅能重新发现已知的物理结构，还能生成新的跨领域假设，为物理学研究提供了新的工具和视角。

Abstract: This work introduces a novel framework for representing and analyzing
physical laws as a weighted knowledge graph. We constructed a database of 659
distinct physical equations, subjected to rigorous semantic cleaning to resolve
notational ambiguities, resulting in a corpus of 400 advanced physics
equations. We developed an enhanced graph representation where both physical
concepts and equations are nodes, connected by weighted inter-equation bridges.
These weights are objectively defined using normalized metrics for variable
overlap, physics-informed importance scores, and bibliometric data. A Graph
Attention Network (GAT) was trained for link prediction, achieving a test AUC
of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming
both classical heuristics (best baseline AUC: 0.9487) and established GNN
architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing
confirmed significance of all comparisons (p < 0.05), with 2.7% improvement
over the best baseline. Our analysis reveals three key findings: (i) The model
autonomously rediscovers the known macroscopic structure of physics,
identifying strong conceptual axes between Electromagnetism and Statistical
Mechanics. (ii) It identifies central hub equations that serve as critical
bridges between multiple physical domains. (iii) The model generates stable,
computationally-derived hypotheses for cross-domain relationships, identifying
both known principles and suggesting novel mathematical analogies for further
theoretical investigation. The framework can generate hundreds of such
hypotheses, enabling the creation of specialized datasets for targeted analysis
of specific physics subfields. Code and data available at
https://github.com/kingelanci/graphysics

</details>


### [63] [Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems](https://arxiv.org/abs/2508.05778)
*Jaemin Oh,Jinsil Lee,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的数据驱动方法，用于学习非线性状态空间模型中的nudging项，并在三个混沌系统上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在非线性系统中设计有效的nudging项具有挑战性，因此需要一种数据驱动的方法来解决这一问题。

Method: 利用神经网络学习非线性状态空间模型中的nudging项，基于Kazantzis--Kravaris--Luenberger观测器理论。

Result: 在Lorenz 96模型、Kuramoto--Sivashinsky方程和Kolmogorov流三个混沌系统上验证了方法的有效性。

Conclusion: 神经网络nudging是一种有效的非线性状态空间模型数据同化方法。

Abstract: Nudging is an empirical data assimilation technique that incorporates an
observation-driven control term into the model dynamics. The trajectory of the
nudged system approaches the true system trajectory over time, even when the
initial conditions differ. For linear state space models, such control terms
can be derived under mild assumptions. However, designing effective nudging
terms becomes significantly more challenging in the nonlinear setting. In this
work, we propose neural network nudging, a data-driven method for learning
nudging terms in nonlinear state space models. We establish a theoretical
existence result based on the Kazantzis--Kravaris--Luenberger observer theory.
The proposed approach is evaluated on three benchmark problems that exhibit
chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and
the Kolmogorov flow.

</details>


### [64] [From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data](https://arxiv.org/abs/2508.05791)
*Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu*

Main category: cs.LG

TL;DR: 提出了一种可扩展的框架，通过整合异构数据重建可信的配电网拓扑，结合空间布局和动态行为，引入置信感知机制，确保物理可行性和不确定性处理。


<details>
  <summary>Details</summary>
Motivation: 配电网拓扑的准确性对现代电网运行至关重要，但实际数据来源多样且质量不均，需要一种可靠的重建方法。

Method: 结合空间布局（如GIS）和动态行为（如电压时间序列），引入置信感知推理机制，并嵌入物理约束（如变压器容量限制）。

Result: 在Oncor的8000多个电表数据上验证，拓扑重建准确率超过95%，置信校准和计算效率显著提升。

Conclusion: 该框架在现实条件下快速收敛到可信拓扑，兼具不确定性感知和结构有效性。

Abstract: Accurate distribution grid topology is essential for reliable modern grid
operations. However, real-world utility data originates from multiple sources
with varying characteristics and levels of quality. In this work, developed in
collaboration with Oncor Electric Delivery, we propose a scalable framework
that reconstructs a trustworthy grid topology by systematically integrating
heterogeneous data. We observe that distribution topology is fundamentally
governed by two complementary dimensions: the spatial layout of physical
infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the
system in the signal domain (e.g., voltage time series). When jointly
leveraged, these dimensions support a complete and physically coherent
reconstruction of network connectivity. To address the challenge of uneven data
quality without compromising observability, we introduce a confidence-aware
inference mechanism that preserves structurally informative yet imperfect
inputs, while quantifying the reliability of each inferred connection for
operator interpretation. This soft handling of uncertainty is tightly coupled
with hard enforcement of physical feasibility: we embed operational
constraints, such as transformer capacity limits and radial topology
requirements, directly into the learning process. Together, these components
ensure that inference is both uncertainty-aware and structurally valid,
enabling rapid convergence to actionable, trustworthy topologies under
real-world deployment conditions. The proposed framework is validated using
data from over 8000 meters across 3 feeders in Oncor's service territory,
demonstrating over 95% accuracy in topology reconstruction and substantial
improvements in confidence calibration and computational efficiency relative to
baseline methods.

</details>


### [65] [Optimal Linear Baseline Models for Scientific Machine Learning](https://arxiv.org/abs/2508.05831)
*Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung*

Main category: cs.LG

TL;DR: 论文提出了一个基于贝叶斯风险最小化的统一理论框架，用于分析线性编码器-解码器架构，适用于科学机器学习问题。


<details>
  <summary>Details</summary>
Motivation: 解决非线性神经网络在可解释性上的不足，为科学机器学习问题提供理论透明的线性模型。

Method: 通过贝叶斯风险最小化，推导出闭式的秩约束线性和仿射线性最优映射，用于正向建模和逆向恢复任务。

Result: 理论结果在生物医学成像、金融因子分析和浅水方程非线性流体动力学模拟中验证。

Conclusion: 该工作为科学机器学习的神经网络模型提供了理论基础和基准。

Abstract: Across scientific domains, a fundamental challenge is to characterize and
compute the mappings from underlying physical processes to observed signals and
measurements. While nonlinear neural networks have achieved considerable
success, they remain theoretically opaque, which hinders adoption in contexts
where interpretability is paramount. In contrast, linear neural networks serve
as a simple yet effective foundation for gaining insight into these complex
relationships. In this work, we develop a unified theoretical framework for
analyzing linear encoder-decoder architectures through the lens of Bayes risk
minimization for solving data-driven scientific machine learning problems. We
derive closed-form, rank-constrained linear and affine linear optimal mappings
for forward modeling and inverse recovery tasks. Our results generalize
existing formulations by accommodating rank-deficiencies in data, forward
operators, and measurement processes. We validate our theoretical results by
conducting numerical experiments on datasets from simple biomedical imaging,
financial factor analysis, and simulations involving nonlinear fluid dynamics
via the shallow water equations. This work provides a robust baseline for
understanding and benchmarking learned neural network models for scientific
machine learning problems.

</details>


### [66] [An Effective Approach for Node Classification in Textual Graphs](https://arxiv.org/abs/2508.05836)
*Rituparna Datta,Nibir Chandra Mandal*

Main category: cs.LG

TL;DR: 提出了一种结合TAPE和Graphormer的新框架，利用ChatGPT生成语义丰富的解释，并通过注意力机制融合文本与结构信息，在ogbn-arxiv数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在文本属性图（TAGs）节点分类中难以整合文本语义与图结构信息的问题。

Method: 结合TAPE框架和Graphormer，利用ChatGPT生成语义解释，并通过注意力机制融合文本与结构特征。

Result: 在ogbn-arxiv数据集上达到0.772的分类准确率，显著优于GCN基线（0.713），并在精确率、召回率和F1分数上表现优异。

Conclusion: 该框架为动态TAGs中的节点分类提供了可扩展且鲁棒的解决方案，为知识系统和科学发现的研究指明了新方向。

Abstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks
like citation networks, but effective node classification remains challenging
due to difficulties in integrating rich semantics from text with structural
graph information. Existing methods often struggle with capturing nuanced
domain-specific terminology, modeling long-range dependencies, adapting to
temporal evolution, and scaling to massive datasets. To address these issues,
we propose a novel framework that integrates TAPE (Text-Attributed Graph
Representation Enhancement) with Graphormer. Our approach leverages a large
language model (LLM), specifically ChatGPT, within the TAPE framework to
generate semantically rich explanations from paper content, which are then
fused into enhanced node representations. These embeddings are combined with
structural features using a novel integration layer with learned attention
weights. Graphormer's path-aware position encoding and multi-head attention
mechanisms are employed to effectively capture long-range dependencies across
the citation network. We demonstrate the efficacy of our framework on the
challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a
classification accuracy of 0.772, significantly surpassing the best GCN
baseline of 0.713. Our method also yields strong results in precision (0.671),
recall (0.577), and F1-score (0.610). We validate our approach through
comprehensive ablation studies that quantify the contribution of each
component, demonstrating the synergy between semantic and structural
information. Our framework provides a scalable and robust solution for node
classification in dynamic TAGs, offering a promising direction for future
research in knowledge systems and scientific discovery.

</details>


### [67] [A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance](https://arxiv.org/abs/2508.05876)
*Francesca Ferrara,Lander W. Schillinger Arana,Florian Dörfler,Sarah H. Q. Li*

Main category: cs.LG

TL;DR: 提出了一种基于MDP和强化学习的碰撞规避决策框架，旨在平衡燃料消耗和碰撞风险。


<details>
  <summary>Details</summary>
Motivation: 在自主导航中，需要平衡碰撞规避的燃料消耗和风险，传统方法可能效率不足。

Method: 使用MDP建模碰撞规避决策，结合强化学习训练策略，优化燃料消耗和风险。

Result: 在合成和历史数据上，训练策略显著降低燃料消耗，同时保持或提高碰撞风险保障。

Conclusion: 该方法在碰撞规避中有效优化燃料使用和风险，优于传统策略。

Abstract: This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.

</details>


### [68] [The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)](https://arxiv.org/abs/2508.05905)
*Jeffrey Uhlmann*

Main category: cs.LG

TL;DR: SZT是一种2位量化方法，在固定资源预算下可能优于非量化方法。


<details>
  <summary>Details</summary>
Motivation: 探讨量化在固定资源预算下的潜在优势，而非仅视为性能与计算资源的折衷。

Method: 提出Signed-Zero Ternary (SZT)，一种2位量化方法，确保梯度信息无前向路径损失。

Result: 分析表明SZT可能提高信息密度，优于非量化方法。

Conclusion: SZT展示了在资源受限场景下量化方法的潜在优势。

Abstract: Quantization is usually regarded as a means to trade quality of performance
for reduced compute requirements, i.e., as a suboptimal approximation. However,
if examined in terms of a fixed overall resource budget, a very different
perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit
quantization that deterministically provides gradient information with no
forward-path penalty. Our analysis provides evidence that it may improve
information density compared to non-quantized alternatives.

</details>


### [69] [Dual Signal Decomposition of Stochastic Time Series](https://arxiv.org/abs/2508.05915)
*Alex Glushkovsky*

Main category: cs.LG

TL;DR: 论文提出了一种将随机时间序列分解为均值、离散度和噪声的方法，通过机器学习拟合双信号并优化损失函数。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列分解中噪声隔离和双信号拟合的问题，以提取均值和离散度的有效信息。

Method: 应用机器学习优化损失函数，结合统计过程控制方法加权正则化项，支持顺序或联合学习方式。

Result: 分解方法可作为平滑或去噪算法，适用于异方差时间序列，并能揭示复杂关系。

Conclusion: 该方法能有效分解时间序列，支持多种应用场景，如预测和结构分析。

Abstract: The research paper addresses decomposition of a stochastic time series into
three time series representing a dual signal i.e., the mean and the dispersion,
with noise isolated. Decomposition is done by applying machine learning to fit
a dual signal. Machine learning minimizes the loss function which compromises
between fitting the original time series and penalizing irregularities of the
dual signal. The latter includes terms based on the first and second order
derivatives along time. To preserve special patterns, weighting of the
regularization components of the loss function has been introduced based on
Statistical Process Control methodology. The proposed decomposition can be
applied as a smoothing algorithm against the mean and dispersion of the time
series. By isolating noise, the proposed decomposition can be seen as a
denoising algorithm. Two approaches of the learning process have been
considered: sequential and jointly. The former approach learns the mean signal
first and then dispersion. The latter approach fits the dual signal jointly.
Jointly learning can uncover complex relationships for the time series with
heteroskedasticity. Learning has been set by solving the direct non-linear
unconstrained optimization problem or by applying neural networks that have
sequential or twin output architectures. Tuning of the loss function
hyperparameters focuses on the isolated noise to be a stationary stochastic
process without autocorrelation properties. Depending on the applications, the
hyperparameters of the learning can be tuned towards either the discrete states
by stepped signal or smoothed series. The decomposed dual signal can be
represented on the 2D space and used to learn inherent structures, to forecast
both mean and dispersion, or to analyze cross effects in case of multiple time
series.

</details>


### [70] [Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations](https://arxiv.org/abs/2508.05921)
*Siddharth Rout*

Main category: cs.LG

TL;DR: 论文提出了一种名为Shifted Gaussian Encoding的方法，用于解决神经PDE求解器中的优化问题，特别是针对多保真度和刚性问题中的病态条件。该方法通过激活过滤提高矩阵秩和表达能力，同时保持凸性。


<details>
  <summary>Details</summary>
Motivation: 神经PDE求解器的精度问题通常源于优化困难，尤其是病态条件导致的收敛限制。论文旨在通过改进激活函数设计来解决这一问题。

Method: 提出了Shifted Gaussian Encoding，一种激活过滤步骤，用于提高矩阵秩和表达能力，同时保持凸性。该方法在Physics-Informed Extreme Learning Machines (PIELMs)中进行了验证。

Result: 该方法将稳态对流-扩散方程的Peclet数可解范围扩展了两个数量级，在多频函数学习中实现了六个数量级的误差降低，并在高保真图像向量拟合中比百万参数深度网络更快更准确。

Conclusion: 研究表明，条件数而非网络深度是科学神经求解器的瓶颈，简单的架构改进可以带来显著的性能提升。

Abstract: Accuracy in neural PDE solvers often breaks down not because of limited
expressivity, but due to poor optimisation caused by ill-conditioning,
especially in multi-fidelity and stiff problems. We study this issue in
Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural
PDE solvers, and show that asymptotic components in governing equations can
produce highly ill-conditioned activation matrices, severely limiting
convergence. We introduce Shifted Gaussian Encoding, a simple yet effective
activation filtering step that increases matrix rank and expressivity while
preserving convexity. Our method extends the solvable range of Peclet numbers
in steady advection-diffusion equations by over two orders of magnitude,
achieves up to six orders lower error on multi-frequency function learning, and
fits high-fidelity image vectors more accurately and faster than deep networks
with over a million parameters. This work highlights that conditioning, not
depth, is often the bottleneck in scientific neural solvers and that simple
architectural changes can unlock substantial gains.

</details>


### [71] [Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting](https://arxiv.org/abs/2508.05928)
*Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu*

Main category: cs.LG

TL;DR: S-GRPO是一种改进的GRPO方法，通过噪声感知优势权重稳定训练，解决了Think-Answer Mismatch问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: GRPO在训练大型推理模型时存在Think-Answer Mismatch问题，尤其是在不平衡响应组中，噪声奖励信号会破坏学习过程。

Method: 提出S-GRPO，通过计算最优噪声感知优势权重来稳定训练。

Result: 在多个数学推理基准测试中，S-GRPO显著优于GRPO，性能提升达2.5%，且在20%合成噪声下仍能稳定学习。

Conclusion: S-GRPO为大规模推理模型的训练提供了更稳健和有效的方法。

Abstract: Group-Relative Policy Optimization (GRPO) is a key technique for training
large reasoning models, yet it suffers from a critical vulnerability: the
\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning
process. This problem is most severe in unbalanced response groups,
paradoxically degrading the signal precisely when it should be most
informative. To address this challenge, we propose Stable Group-Relative Policy
Optimization (S-GRPO), a principled enhancement that derives optimal,
noise-aware advantage weights to stabilize training. Our comprehensive
experiments on mathematical reasoning benchmarks demonstrate S-GRPO's
effectiveness and robustness. On various models, S-GRPO significantly
outperforms DR. GRPO, achieving performance gains of +2.5% on
Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on
Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn
under 20% synthetic reward noise, S-GRPO maintains stable learning progress.
These results highlight S-GRPO's potential for more robust and effective
training of large-scale reasoning models. \footnote{Code and data are available
at: https://github.com/shenpeijun0212/S-GRPO

</details>


### [72] [Multi-Armed Bandits-Based Optimization of Decision Trees](https://arxiv.org/abs/2508.05957)
*Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman*

Main category: cs.LG

TL;DR: 论文提出了一种基于多臂老虎机（MAB）的决策树剪枝方法，通过强化学习动态优化剪枝过程，以提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法（如CCP和REP）基于贪心策略，可能导致泛化能力下降，尤其是在小规模复杂数据集上。

Method: 将剪枝过程建模为探索-利用问题，利用MAB算法动态选择最优剪枝节点。

Result: 实验表明，该方法在多个基准数据集上优于传统剪枝方法。

Conclusion: MAB剪枝方法为决策树优化提供了一种动态且概率化的新思路。

Abstract: Decision trees, without appropriate constraints, can easily become overly
complex and prone to overfit, capturing noise rather than generalizable
patterns. To resolve this problem,pruning operation is a crucial part in
optimizing decision trees, as it not only reduces the complexity of trees but
also decreases the probability of generating overfit models. The conventional
pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning
(REP) are mostly based on greedy approaches that focus on immediate gains in
performance while pruning nodes of the decision tree. However, this might
result in a lower generalization in the long run, compromising the robust
ability of the tree model when introduced to unseen data samples, particularly
when trained with small and complex datasets. To address this challenge, we are
proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement
learning (RL)-based technique, that will dynamically prune the tree to generate
an optimal decision tree with better generalization. Our proposed approach
assumes the pruning process as an exploration-exploitation problem, where we
are utilizing the MAB algorithms to find optimal branch nodes to prune based on
feedback from each pruning actions. Experimental evaluation on several
benchmark datasets, demonstrated that our proposed approach results in better
predictive performance compared to the traditional ones. This suggests the
potential of utilizing MAB for a dynamic and probabilistic way of decision tree
pruning, in turn optimizing the decision tree-based model.

</details>


### [73] [Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2508.05960)
*Haohui Chen,Zhiyong Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为MCRE的框架，通过结合TD误差和行为克隆项来平衡保守性和性能，并基于此开发了MCRQ算法，实验表明其在离线RL任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习面临分布偏移问题，导致OOD动作和过高估计，需要平衡保守性和性能提升。

Method: 提出MCRE框架，结合TD误差和行为克隆项；开发MCRQ算法，将MCRE融入离线actor-critic框架。

Result: MCRQ在基准数据集上优于现有离线RL算法和基线方法。

Conclusion: MCRE和MCRQ有效解决了离线RL中的保守性与性能平衡问题，具有显著优势。

Abstract: Offline reinforcement learning (RL) seeks to learn optimal policies from
static datasets without further environment interaction. A key challenge is the
distribution shift between the learned and behavior policies, leading to
out-of-distribution (OOD) actions and overestimation. To prevent gross
overestimation, the value function must remain conservative; however, excessive
conservatism may hinder performance improvement. To address this, we propose
the mildly conservative regularized evaluation (MCRE) framework, which balances
conservatism and performance by combining temporal difference (TD) error with a
behavior cloning term in the Bellman backup. Building on this, we develop the
mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates
MCRE into an off-policy actor-critic framework. Experiments show that MCRQ
outperforms strong baselines and state-of-the-art offline RL algorithms on
benchmark datasets.

</details>


### [74] [LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning](https://arxiv.org/abs/2508.05977)
*Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan*

Main category: cs.LG

TL;DR: 提出了一种基于语义对齐的强化学习方法，利用SBERT计算奖励，替代传统手动设计的奖励函数，在多环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在科学机器学习中，设计有效的奖励函数是一个挑战，尤其是在任务目标难以数值化的环境中。传统方法依赖启发式或手动设计，缺乏普适性。

Method: 通过SBERT计算当前状态与目标语义指令的余弦相似度作为奖励，替代手动设计的奖励函数。

Result: 在多个环境中验证了语义奖励能够指导学习，实现竞争性控制行为，且无需手动设计奖励函数。

Conclusion: 该方法展示了语言嵌入空间与传统欧几里得空间的关联，为自然语言目标与智能体行为的对齐提供了新思路，并为大语言模型与控制应用的集成奠定了基础。

Abstract: In the domain of scientific machine learning, designing effective reward
functions remains a challenge in reinforcement learning (RL), particularly in
environments where task goals are difficult to specify numerically. Reward
functions in existing work are predominantly based on heuristics, manual
engineering, or task-specific tuning. In this work, we introduce a semantically
aligned reinforcement learning method where rewards are computed by aligning
the current state with a target semantic instruction using a
Sentence-Bidirectional Encoder Representations from Transformers (SBERT).
Instead of relying on manually defined reward functions, the policy receives
feedback based on the reward, which is a cosine similarity between the goal
textual description and the statement description in the episode. We evaluated
our approach in several environments and showed that semantic reward can guide
learning to achieve competitive control behavior, even in the absence of
hand-crafted reward functions. Our study demonstrates a correlation between the
language embedding space and the conventional Euclidean space. This framework
opens new horizons for aligning agent behavior with natural language goals and
lays the groundwork for a more seamless integration of larger language models
(LLMs) and fluid control applications.

</details>


### [75] [Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning](https://arxiv.org/abs/2508.05984)
*Ankur Naskar,Gugan Thoppe,Vijay Gupta*

Main category: cs.LG

TL;DR: 论文提出了一种新方法，通过重新定义误差和结合半范数收缩与诱导范数的单调性，首次实现了参数无关的$\tilde{O}(1/\sqrt{t})$最优收敛速率，适用于平均奖励和指数折扣的$Q$-学习。


<details>
  <summary>Details</summary>
Motivation: 解决非线性固定点方程（如$Q$-学习和TD学习）中半范数收缩导致的非单调性问题，实现参数无关的最优收敛速率。

Method: 将平均误差重新定义为涉及非线性扰动的线性递归，并通过结合半范数收缩与诱导范数的单调性来控制非线性。

Result: 首次实现了参数无关的$\tilde{O}(1/\sqrt{t})$最优收敛速率，适用于多种场景（同步/异步、单智能体/分布式、模拟器/马尔可夫轨迹）。

Conclusion: 该方法为$Q$-学习提供了广泛适用的最优收敛速率，解决了长期存在的非单调性问题。

Abstract: Algorithms for solving \textit{nonlinear} fixed-point equations -- such as
average-reward \textit{$Q$-learning} and \textit{TD-learning} -- often involve
semi-norm contractions. Achieving parameter-free optimal convergence rates for
these methods via Polyak--Ruppert averaging has remained elusive, largely due
to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting
the averaged error as a linear recursion involving a nonlinear perturbation,
and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with
the monotonicity of a suitably induced norm. Our main result yields the first
parameter-free $\tilde{O}(1/\sqrt{t})$ optimal rates for $Q$-learning in both
average-reward and exponentially discounted settings, where $t$ denotes the
iteration index. The result applies within a broad framework that accommodates
synchronous and asynchronous updates, single-agent and distributed deployments,
and data streams obtained either from simulators or along Markovian
trajectories.

</details>


### [76] [Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal](https://arxiv.org/abs/2508.05988)
*Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu*

Main category: cs.LG

TL;DR: ASAP是一种新颖的CoT压缩框架，通过锚点引导和意外性度量，显著减少推理延迟和训练成本，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决长推理链带来的训练成本高、推理延迟大和部署困难的问题，同时避免现有压缩方法破坏逻辑连贯性或无法捕捉关键推理步骤的缺陷。

Method: ASAP采用粗到细的框架：1) 锚点引导剪枝保留核心推理结构；2) 基于首词意外性度量的逻辑感知剪枝；3) 模型自主生成简洁CoT。

Result: 在多个代码生成基准测试中达到最优准确性，LiveCodeBench v4_v5上减少23.5%的token生成和43.5%的推理延迟，Pass@1准确率为36.19%。

Conclusion: ASAP为构建高效且强大的LRMs提供了有前景的方向。

Abstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable
capabilities in code reasoning by scaling up the length of Chain-of-Thought
(CoT). However, excessively long reasoning traces introduce substantial
challenges in terms of training cost, inference latency, and deployment
feasibility. While various CoT compression approaches have emerged to address
this challenge, they face inherent trade-offs: token-level methods often
disrupt syntactic and logical coherence, while step-level methods based on
perplexity fail to reliably capture the logically critical reasoning steps. In
this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel
coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided
pruning to preserve the core reasoning structure, which efficiently reduces the
search space for subsequent processing. It then enables a logic-aware pruning
by selecting logically essential reasoning steps based on a novel first-token
surprisal metric. Finally, ASAP teaches models to autonomously generate and
leverage these concise CoTs at inference time, enabling efficient reasoning in
coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy
across multiple code generation benchmarks while substantially reducing
training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,
our approach reduces token generation by 23.5% and inference latency by 43.5%
compared to the strongest baseline, while achieving a competitive accuracy of
36.19% in Pass@1. Our results highlight a promising direction for building
powerful and efficient LRMs.

</details>


### [77] [Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization](https://arxiv.org/abs/2508.05995)
*Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: MCTS-OPS结合MCTS和LLM，通过多步提示序列提升代码生成质量和问题解决能力，在复杂优化任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码生成和结构化推理方面表现出色，但在需要多步规划的复杂任务中性能下降。现有方法多关注启发式代码生成或简单任务，缺乏对复杂优化的支持。

Method: 提出MCTS-OPS框架，将提示选择建模为MCTS引导的序列决策过程，探索并优化多步提示序列。

Result: 在网络优化实验中，MCTS-OPS在代码执行成功率和优化结果上显著优于基线（奖励提高2~4倍，标准差降低3倍），且在困难问题中达到最优解的概率提高约10%。

Conclusion: 结合符号规划和LLM的方法在复杂领域中展现出高质量代码生成的潜力。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
code generation and structured reasoning; however, their performance often
degrades on complex tasks that require consistent multi-step planning. Recent
work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet
existing approaches primarily focus on generating heuristic-based code for
optimization or target simpler tasks where correctness alone is sufficient. In
this work, we propose MCTS-OPS, a novel neural-symbolic framework that
formulates prompt selection as a sequential decision process guided by MCTS.
Our method explores and refines multi-step prompt sequences for the goal of
improving code generation quality and enhancing the problem-solving
capabilities of LLMs in general optimization. Experiments on network
optimization show significant improvement over the baselines, both in the
success rate of executing the generated code and in the optimization results
with the specified objective and constraints (2$\sim$4$\times$ higher reward
and 3$\times$ lower standard deviation). Moreover, it improves the chance of
attaining the optimal solution by about 10\% of cases, compared to baseline
methods in hard problems. These results highlight the promise of combining
symbolic planning with LLMs for robust, high-quality code generation in complex
domains.

</details>


### [78] [Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients](https://arxiv.org/abs/2508.06023)
*Xiaobin Shen,Jonathan Elmer,George H. Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的逐步动态竞争风险模型，用于改善心脏骤停后昏迷患者的神经预后预测，通过分阶段利用时间不变和时间变化特征。


<details>
  <summary>Details</summary>
Motivation: 心脏骤停后昏迷患者的预后预测对ICU临床决策至关重要，但目前的方法未能充分利用随时间变化的动态特征。

Method: 研究扩展了Fine and Gray模型，引入神经网络分阶段建模时间不变和时间变化特征，并自动确定何时利用这些特征。

Result: 在2278名患者的回顾性队列中，模型对觉醒、停止生命支持治疗和死亡等竞争结局表现出强大的判别性能。

Conclusion: 该模型可推广至多阶段特征收集的动态预测任务，为临床决策提供更精准的预后信息。

Abstract: Prognostication for comatose post-cardiac arrest patients is a critical
challenge that directly impacts clinical decision-making in the ICU. Clinical
information that informs prognostication is collected serially over time.
Shortly after cardiac arrest, various time-invariant baseline features are
collected (e.g., demographics, cardiac arrest characteristics). After ICU
admission, additional features are gathered, including time-varying hemodynamic
data (e.g., blood pressure, doses of vasopressor medications). We view these as
two phases in which we collect new features. In this study, we propose a novel
stepwise dynamic competing risks model that improves the prediction of
neurological outcomes by automatically determining when to take advantage of
time-invariant features (first phase) and time-varying features (second phase).
Notably, our model finds patients for whom this second phase (time-varying
hemodynamic) information is beneficial for prognostication and also when this
information is beneficial (as we collect more hemodynamic data for a patient
over time, how important these data are for prognostication varies). Our
approach extends the standard Fine and Gray model to explicitly model the two
phases and to incorporate neural networks to flexibly capture complex nonlinear
feature relationships. Evaluated on a retrospective cohort of 2,278 comatose
post-arrest patients, our model demonstrates robust discriminative performance
for the competing outcomes of awakening, withdrawal of life-sustaining therapy,
and death despite maximal support. Our approach generalizes to more than two
phases in which new features are collected and could be used in other dynamic
prediction tasks, where it may be helpful to know when and for whom newly
collected features significantly improve prediction.

</details>


### [79] [Unsupervised Partner Design Enables Robust Ad-hoc Teamwork](https://arxiv.org/abs/2508.06336)
*Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling*

Main category: cs.LG

TL;DR: UPD是一种无监督的伙伴设计框架，通过动态生成多样化的训练伙伴，提升多智能体强化学习中的协作能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要预训练伙伴或手动调参的问题，实现完全无监督的伙伴和关卡分布课程。

Method: 通过随机混合自我策略与偏置随机行为生成多样化伙伴，并使用基于方差的易学性指标评分。

Result: 在Overcooked-AI和挑战赛中表现优异，优于基线方法，用户研究显示其更适应、更人性化。

Conclusion: UPD是一种高效的无监督伙伴设计方法，显著提升了协作任务的性能。

Abstract: We introduce Unsupervised Partner Design (UPD) - a population-free,
multi-agent reinforcement learning framework for robust ad-hoc teamwork that
adaptively generates training partners without requiring pretrained partners or
manual parameter tuning. UPD constructs diverse partners by stochastically
mixing an ego agent's policy with biased random behaviours and scores them
using a variance-based learnability metric that prioritises partners near the
ego agent's current learning frontier. We show that UPD can be integrated with
unsupervised environment design, resulting in the first method enabling fully
unsupervised curricula over both level and partner distributions in a
cooperative setting. Through extensive evaluations on Overcooked-AI and the
Overcooked Generalisation Challenge, we demonstrate that this dynamic partner
curriculum is highly effective: UPD consistently outperforms both
population-based and population-free baselines as well as ablations. In a user
study, we further show that UPD achieves higher returns than all baselines and
was perceived as significantly more adaptive, more human-like, a better
collaborator, and less frustrating.

</details>


### [80] [Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity](https://arxiv.org/abs/2508.06034)
*Qin Chen,Guojie Song*

Main category: cs.LG

TL;DR: 论文提出了一种自适应异构图神经网络（AHGNN），解决了异构图中的异质性分布和语义多样性问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实中的异构图常表现出异质性，但现有研究多孤立关注异质性或异质性，忽略了异质性异构图的普遍性，导致性能下降。

Method: 提出AHGNN，采用异质性感知卷积和粗到细的注意力机制，处理异质性分布和语义多样性。

Result: 在七个真实世界图和二十个基线上的实验表明，AHGNN在高异质性情况下表现优越。

Conclusion: AHGNN有效解决了异质性异构图的建模挑战，具有实际应用潜力。

Abstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often
exhibit heterophily. However, most existing studies focus on either
heterogeneity or heterophily in isolation, overlooking the prevalence of
heterophilic HGs in practical applications. Such ignorance leads to their
performance degradation. In this work, we first identify two main challenges in
modeling heterophily HGs: (1) varying heterophily distributions across hops and
meta-paths; (2) the intricate and often heterophily-driven diversity of
semantic information across different meta-paths. Then, we propose the Adaptive
Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN
employs a heterophily-aware convolution that accounts for heterophily
distributions specific to both hops and meta-paths. It then integrates messages
from diverse semantic spaces using a coarse-to-fine attention mechanism, which
filters out noise and emphasizes informative signals. Experiments on seven
real-world graphs and twenty baselines demonstrate the superior performance of
AHGNN, particularly in high-heterophily situations.

</details>


### [81] [DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment](https://arxiv.org/abs/2508.06041)
*Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park*

Main category: cs.LG

TL;DR: DP-LLM通过动态分配精度，优化了设备上大型语言模型的性能与延迟权衡。


<details>
  <summary>Details</summary>
Motivation: 解决在设备上运行大型语言模型时，如何根据动态变化的运行时约束（如延迟和精度）有效配置模型的问题。

Method: 提出DP-LLM机制，动态为每个层分配精度，利用轻量级误差估计器和阈值进行运行时调整。

Result: 实验表明，DP-LLM在性能与延迟的权衡上优于现有方法。

Conclusion: DP-LLM为动态精度分配提供了有效解决方案，适用于设备上的大型语言模型。

Abstract: How can we effectively handle queries for on-device large language models
(LLMs) with varying runtime constraints, such as latency and accuracy?
Multi-scale quantization addresses this challenge by enabling memory-efficient
runtime model adaptation of LLMs through the overlaying of multiple model
variants quantized to different bitwidths. Meanwhile, an important question
still remains open-ended: how can models be properly configured to match a
target precision or latency? While mixed-precision offers a promising solution,
we take this further by leveraging the key observation that the sensitivity of
each layer dynamically changes across decoding iterations. Building on this
insight, we introduce DP-LLM, a novel mechanism that dynamically assigns
precision to each layer based on input values. DP-LLM augments each linear
layer in an LLM with a precision selector that determines the bitwidth at
runtime using a lightweight error estimator and threshold values learned
through fine-tuning. Experimental results across multiple models and benchmarks
demonstrate that DP-LLM achieves a superior performance-latency trade-off,
outperforming prior approaches.

</details>


### [82] [Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology](https://arxiv.org/abs/2508.06066)
*Barak Gahtan,Alex M. Bronstein*

Main category: cs.LG

TL;DR: 该论文提出了针对深度时间模型（如TCNs）的首个非空泛、架构感知的泛化界限，并引入了一种公平比较的方法论。研究发现，时间依赖性可以在固定信息预算下增强学习，但理论与实际存在差距。


<details>
  <summary>Details</summary>
Motivation: 理解深度时间模型的泛化性能，填补理论空白，并提供一个评估方法论。

Method: 通过延迟反馈阻塞机制将依赖样本转化为有效独立样本，推导出泛化界限，并设计公平比较方法。

Result: 泛化界限为$O(R\sqrt{Dpn\log N/N})$，时间依赖性强的序列泛化差距比依赖性弱的小76%。

Conclusion: 时间依赖性可以优化学习，但理论与实际收敛速率存在差异，需进一步研究。

Abstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs)
achieve strong predictive performance on sequential data, yet theoretical
understanding of their generalization remains limited. We address this gap by
providing both the first non-vacuous, architecture-aware generalization bounds
for deep temporal models and a principled evaluation methodology.
  For exponentially $\beta$-mixing sequences, we derive bounds scaling as $
O\!\Bigl(R\,\sqrt{\tfrac{D\,p\,n\,\log N}{N}}\Bigr), $ where $D$ is network
depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our
delayed-feedback blocking mechanism transforms dependent samples into
effectively independent ones while discarding only $O(1/\log N)$ of the data,
yielding $\sqrt{D}$ scaling instead of exponential, implying that doubling
depth requires approximately quadrupling the training data.
  We also introduce a fair-comparison methodology that fixes the effective
sample size to isolate the effect of temporal structure from information
content. Under $N_{\text{eff}}=2{,}000$, strongly dependent sequences
($\rho=0.8$) exhibit $\approx76\%$ smaller generalization gaps than weakly
dependent ones ($\rho=0.2$), challenging the intuition that dependence is
purely detrimental. Yet convergence rates diverge from theory: weak
dependencies follow $N_{\text{eff}}^{-1.21}$ scaling and strong dependencies
follow $N_{\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.
These findings reveal that temporal dependence can enhance learning under fixed
information budgets, while highlighting gaps between theory and practice that
motivate future research.

</details>


### [83] [Recurrent Deep Differentiable Logic Gate Networks](https://arxiv.org/abs/2508.06097)
*Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 论文首次实现了循环深度可微分逻辑门网络（RDDLGN），将布尔运算与循环架构结合用于序列到序列学习，在WMT'14英德翻译任务中表现接近GRU。


<details>
  <summary>Details</summary>
Motivation: 探索可微分逻辑门在序列建模中的应用，填补其在循环架构中的空白。

Method: 结合布尔运算与循环架构，提出RDDLGN模型。

Result: 在WMT'14英德翻译任务中，RDDLGN达到5.00 BLEU和30.9%训练准确率，接近GRU性能（5.41 BLEU）。

Conclusion: RDDLGN证明了基于循环逻辑的神经计算的可行性，为FPGA加速等研究方向开辟了道路。

Abstract: While differentiable logic gates have shown promise in feedforward networks,
their application to sequential modeling remains unexplored. This paper
presents the first implementation of Recurrent Deep Differentiable Logic Gate
Networks (RDDLGN), combining Boolean operations with recurrent architectures
for sequence-to-sequence learning.
  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and
30.9\% accuracy during training, approaching GRU performance (5.41 BLEU) and
graceful degradation (4.39 BLEU) during inference. This work establishes
recurrent logic-based neural computation as viable, opening research directions
for FPGA acceleration in sequential modeling and other recursive network
architectures.

</details>


### [84] [GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2508.06108)
*Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Hindsight Goal-conditioned Regularization (HGR)的技术，结合Hindsight Self-imitation Regularization (HSR)，显著提高了稀疏奖励目标导向强化学习（GCRL）的样本效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏奖励的目标导向强化学习（GCRL）面临样本效率低下的挑战，现有的Hindsight Experience Replay (HER)方法未能充分利用经验。

Method: 提出HGR技术，基于后见目标生成动作正则化先验，并结合HSR，最大化经验利用率。

Result: 在导航和操作任务上，HGR和HSR的组合显著优于现有方法，实现了更高的样本效率和性能。

Conclusion: HGR和HSR的组合为稀疏奖励GCRL提供了一种高效的解决方案，显著提升了样本重用和任务性能。

Abstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a
fundamental challenge in reinforcement learning. While hindsight experience
replay (HER) has shown promise by relabeling collected trajectories with
achieved goals, we argue that trajectory relabeling alone does not fully
exploit the available experiences in off-policy GCRL methods, resulting in
limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned
Regularization (HGR), a technique that generates action regularization priors
based on hindsight goals. When combined with hindsight self-imitation
regularization (HSR), our approach enables off-policy RL algorithms to maximize
experience utilization. Compared to existing GCRL methods that employ HER and
self-imitation techniques, our hindsight regularizations achieve substantially
more efficient sample reuse and the best performances, which we empirically
demonstrate on a suite of navigation and manipulation tasks.

</details>


### [85] [Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models](https://arxiv.org/abs/2508.06151)
*Yong Oh Lee,JeeEun Kim,Jung Woo Lee*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型的图像修复技术，用于生成高保真口腔癌病变图像，显著提升了诊断模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决口腔癌诊断中标注数据不足和训练数据多样性的问题。

Method: 使用微调的扩散模型和图像修复技术生成合成病变图像，并结合多源数据集。

Result: 分类模型准确率达0.97，检测模型定位准确率达0.85。

Conclusion: 验证了合成图像在医学诊断中的潜力，为其他癌症诊断方法的研究提供了方向。

Abstract: In oral cancer diagnostics, the limited availability of annotated datasets
frequently constrains the performance of diagnostic models, particularly due to
the variability and insufficiency of training data. To address these
challenges, this study proposed a novel approach to enhance diagnostic accuracy
by synthesizing realistic oral cancer lesions using an inpainting technique
with a fine-tuned diffusion model. We compiled a comprehensive dataset from
multiple sources, featuring a variety of oral cancer images. Our method
generated synthetic lesions that exhibit a high degree of visual fidelity to
actual lesions, thereby significantly enhancing the performance of diagnostic
algorithms. The results show that our classification model achieved a
diagnostic accuracy of 0.97 in differentiating between cancerous and
non-cancerous tissues, while our detection model accurately identified lesion
locations with 0.85 accuracy. This method validates the potential for synthetic
image generation in medical diagnostics and paves the way for further research
into extending these methods to other types of cancer diagnostics.

</details>


### [86] [Differentially Private Federated Clustering with Random Rebalancing](https://arxiv.org/abs/2508.06183)
*Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li*

Main category: cs.LG

TL;DR: RR-Cluster是一种轻量级技术，通过随机重新平衡集群分配来减少隐私噪声，提高联邦聚类中的隐私/效用权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类通过为每个集群训练一个模型来提高性能，但可能导致隐私泄露。直接应用差分隐私机制会显著降低效用。

Method: 提出RR-Cluster技术，通过强制每个集群分配最小数量的客户端来减少隐私噪声。

Result: RR-Cluster显著改善了隐私/效用权衡，并在合成和真实数据集上验证了其有效性。

Conclusion: RR-Cluster是一种简单有效的技术，可提升联邦聚类算法的隐私保护能力，同时保持模型性能。

Abstract: Federated clustering aims to group similar clients into clusters and produce
one model for each cluster. Such a personalization approach typically improves
model performance compared with training a single model to serve all clients,
but can be more vulnerable to privacy leakage. Directly applying client-level
differentially private (DP) mechanisms to federated clustering could degrade
the utilities significantly. We identify that such deficiencies are mainly due
to the difficulties of averaging privacy noise within each cluster (following
standard privacy mechanisms), as the number of clients assigned to the same
clusters is uncontrolled. To this end, we propose a simple and effective
technique, named RR-Cluster, that can be viewed as a light-weight add-on to
many federated clustering algorithms. RR-Cluster achieves reduced privacy noise
via randomly rebalancing cluster assignments, guaranteeing a minimum number of
clients assigned to each cluster. We analyze the tradeoffs between decreased
privacy noise variance and potentially increased bias from incorrect
assignments and provide convergence bounds for RR-Clsuter. Empirically, we
demonstrate the RR-Cluster plugged into strong federated clustering algorithms
results in significantly improved privacy/utility tradeoffs across both
synthetic and real-world datasets.

</details>


### [87] [Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning](https://arxiv.org/abs/2508.06199)
*Mateusz Praski,Jakub Adamczyk,Wojciech Czech*

Main category: cs.LG

TL;DR: 该研究对25种预训练神经网络模型进行了广泛比较，发现大多数模型在分子化学任务中表现与基线ECFP指纹相当，仅CLAMP模型显著优于其他。


<details>
  <summary>Details</summary>
Motivation: 评估预训练神经网络在分子化学任务中的实际效果，揭示现有研究的评估严谨性问题。

Method: 使用公平比较框架和分层贝叶斯统计测试模型，评估25种模型在25个数据集上的表现。

Result: 大多数神经网络模型表现与基线ECFP指纹相当，仅CLAMP模型显著优于其他。

Conclusion: 研究揭示了现有评估的不足，提出了改进建议，并强调需要更严格的评估标准。

Abstract: Pretrained neural networks have attracted significant interest in chemistry
and small molecule drug design. Embeddings from these models are widely used
for molecular property prediction, virtual screening, and small data learning
in molecular chemistry. This study presents the most extensive comparison of
such models to date, evaluating 25 models across 25 datasets. Under a fair
comparison framework, we assess models spanning various modalities,
architectures, and pretraining strategies. Using a dedicated hierarchical
Bayesian statistical testing model, we arrive at a surprising result: nearly
all neural models show negligible or no improvement over the baseline ECFP
molecular fingerprint. Only the CLAMP model, which is also based on molecular
fingerprints, performs statistically significantly better than the
alternatives. These findings raise concerns about the evaluation rigor in
existing studies. We discuss potential causes, propose solutions, and offer
practical recommendations.

</details>


### [88] [Graph Federated Learning for Personalized Privacy Recommendation](https://arxiv.org/abs/2508.06208)
*Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang*

Main category: cs.LG

TL;DR: GFed-PP是一种新型的联邦推荐系统，适应不同隐私需求并提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统假设所有用户隐私需求相同，忽略了公开用户数据的潜力。

Method: 利用公开用户数据构建用户-项目交互图，结合轻量级GCN学习个性化嵌入，本地保护隐私。

Result: 在五个数据集上显著优于现有方法，推荐准确性高且隐私保护强。

Conclusion: GFed-PP为联邦推荐系统中多样化隐私需求提供了实用解决方案。

Abstract: Federated recommendation systems (FedRecs) have gained significant attention
for providing privacy-preserving recommendation services. However, existing
FedRecs assume that all users have the same requirements for privacy
protection, i.e., they do not upload any data to the server. The approaches
overlook the potential to enhance the recommendation service by utilizing
publicly available user data. In real-world applications, users can choose to
be private or public. Private users' interaction data is not shared, while
public users' interaction data can be shared. Inspired by the issue, this paper
proposes a novel Graph Federated Learning for Personalized Privacy
Recommendation (GFed-PP) that adapts to different privacy requirements while
improving recommendation performance. GFed-PP incorporates the interaction data
of public users to build a user-item interaction graph, which is then used to
form a user relationship graph. A lightweight graph convolutional network (GCN)
is employed to learn each user's user-specific personalized item embedding. To
protect user privacy, each client learns the user embedding and the scoring
function locally. Additionally, GFed-PP achieves optimization of the federated
recommendation framework through the initialization of item embedding on
clients and the aggregation of the user relationship graph on the server.
Experimental results demonstrate that GFed-PP significantly outperforms
existing methods for five datasets, offering superior recommendation accuracy
without compromising privacy. This framework provides a practical solution for
accommodating varying privacy preferences in federated recommendation systems.

</details>


### [89] [Reparameterization Proximal Policy Optimization](https://arxiv.org/abs/2508.06214)
*Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang*

Main category: cs.LG

TL;DR: 论文提出了一种稳定的重参数化策略梯度方法（RPO），通过结合PPO的代理目标和KL散度正则化，解决了RPG训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 重参数化策略梯度（RPG）在样本效率上有潜力，但训练不稳定，梯度方差高。

Method: 将PPO的代理目标与RPG结合，提出RPO，通过时间反向传播高效计算梯度，并引入KL散度正则化。

Result: 在运动和操作任务上，RPO表现出优异的样本效率和性能。

Conclusion: RPO是一种稳定且高效的RPG方法，适用于复杂任务。

Abstract: Reparameterization policy gradient (RPG) is promising for improving sample
efficiency by leveraging differentiable dynamics. However, a critical barrier
is its training instability, where high-variance gradients can destabilize the
learning process. To address this, we draw inspiration from Proximal Policy
Optimization (PPO), which uses a surrogate objective to enable stable sample
reuse in the model-free setting. We first establish a connection between this
surrogate objective and RPG, which has been largely unexplored and is
non-trivial. Then, we bridge this gap by demonstrating that the
reparameterization gradient of a PPO-like surrogate objective can be computed
efficiently using backpropagation through time. Based on this key insight, we
propose Reparameterization Proximal Policy Optimization (RPO), a stable and
sample-efficient RPG-based method. RPO enables multiple epochs of stable sample
reuse by optimizing a clipped surrogate objective tailored for RPG, while being
further stabilized by Kullback-Leibler (KL) divergence regularization and
remaining fully compatible with existing variance reduction methods. We
evaluate RPO on a suite of challenging locomotion and manipulation tasks, where
experiments demonstrate that our method achieves superior sample efficiency and
strong performance.

</details>


### [90] [SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems](https://arxiv.org/abs/2508.06243)
*Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian*

Main category: cs.LG

TL;DR: SCAR是一种基于边缘AI的资源管理框架，通过ML压缩技术优化6G车载娱乐网络的调度和公平性，提升吞吐量并减少不公平调度。


<details>
  <summary>Details</summary>
Motivation: 传统RRM技术难以处理6G车载网络中复杂的数据（如CQI），需要一种更高效的资源管理方法。

Method: SCAR使用ML压缩技术（如聚类和RBF网络）减少CQI数据量，并利用强化学习策略优化调度和公平性。

Result: SCAR将可行调度区域时间增加14%，不公平调度时间减少15%，且CQI聚类失真降低10%。

Conclusion: SCAR在动态车载网络中展现出良好的可扩展性和公平性优势。

Abstract: The advent of 6G networks opens new possibilities for connected infotainment
services in vehicular environments. However, traditional Radio Resource
Management (RRM) techniques struggle with the increasing volume and complexity
of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To
address this, we propose SCAR (State-Space Compression for AI-Driven Resource
Management), an Edge AI-assisted framework that optimizes scheduling and
fairness in vehicular infotainment. SCAR employs ML-based compression
techniques (e.g., clustering and RBF networks) to reduce CQI data size while
preserving essential features. These compressed states are used to train
6G-enabled Reinforcement Learning policies that maximize throughput while
meeting fairness objectives defined by the NGMN. Simulations show that SCAR
increases time in feasible scheduling regions by 14\% and reduces unfair
scheduling time by 15\% compared to RL baselines without CQI compression.
Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based
clustering reduces CQI clustering distortion by 10\%, confirming its
efficiency. These results demonstrate SCAR's scalability and fairness benefits
for dynamic vehicular networks.

</details>


### [91] [Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient](https://arxiv.org/abs/2304.04475)
*Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 论文提出了一种基于DDPG的策略优化框架，用于在大规模流行病模拟中自动确定最优干预措施（如封锁和疫苗接种），以平衡健康和经济目标。


<details>
  <summary>Details</summary>
Motivation: 现有研究在模拟目标、规模和干预策略探索方面存在局限性，无法有效确定最优干预措施。

Method: 使用DDPG策略优化框架，结合大规模（10万个体）流行病学基于代理的模拟，进行多目标优化。

Result: 在无封锁和针对中老年人群的疫苗接种策略下，实现了经济（贫困线以下人口）与健康目标（感染和住院）的平衡。

Conclusion: 研究为自动优化干预措施提供了可行框架，但需进一步验证和开源框架。

Abstract: To mitigate the impact of the pandemic, several measures include lockdowns,
rapid vaccination programs, school closures, and economic stimulus. These
interventions can have positive or unintended negative consequences. Current
research to model and determine an optimal intervention automatically through
round-tripping is limited by the simulation objectives, scale (a few thousand
individuals), model types that are not suited for intervention studies, and the
number of intervention strategies they can explore (discrete vs continuous). We
address these challenges using a Deep Deterministic Policy Gradient (DDPG)
based policy optimization framework on a large-scale (100,000 individual)
epidemiological agent-based simulation where we perform multi-objective
optimization. We determine the optimal policy for lockdown and vaccination in a
minimalist age-stratified multi-vaccine scenario with a basic simulation for
economic activity. With no lockdown and vaccination (mid-age and elderly),
results show optimal economy (individuals below the poverty line) with balanced
health objectives (infection, and hospitalization). An in-depth simulation is
needed to further validate our results and open-source our framework.

</details>


### [92] [Membership Inference Attack with Partial Features](https://arxiv.org/abs/2508.06244)
*Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang*

Main category: cs.LG

TL;DR: 论文研究了在部分特征信息可用的情况下进行成员推理攻击的问题，提出了MRAD框架，通过优化未知特征值和异常检测来有效推断样本是否在训练集中。


<details>
  <summary>Details</summary>
Motivation: 现有成员推理方法通常假设攻击者能访问目标样本的全部特征，但现实中往往只有部分特征可用，限制了这些方法的适用性。

Method: 提出MRAD框架，分为两阶段：1）优化未知特征值以最小化样本损失；2）通过异常检测测量重建样本与训练分布的偏差。

Result: 实验表明MRAD在多种数据集上有效，例如在STL-10上，即使缺失40%特征，AUC仍可达0.6。

Conclusion: MRAD解决了部分特征下的成员推理问题，兼容多种异常检测技术，具有实际应用价值。

Abstract: Machine learning models have been shown to be susceptible to membership
inference attack, which can be used to determine whether a given sample appears
in the training data. Existing membership inference methods commonly assume
that the adversary has full access to the features of the target sample. This
assumption, however, does not hold in many real-world scenarios where only
partial features information is available, thereby limiting the applicability
of these methods. In this work, we study an inference scenario where the
adversary observes only partial features of each sample and aims to infer
whether this observed subset was present in the training set of the target
model. We define this problem as Partial Feature Membership Inference (PFMI).
To address this problem, we propose MRAD (Memory-guided Reconstruction and
Anomaly Detection), a two-stage attack framework. In the first stage, MRAD
optimizes the unknown feature values to minimize the loss of the sample. In the
second stage, it measures the deviation between the reconstructed sample and
the training distribution using anomaly detection. Empirical results
demonstrate that MRAD is effective across a range of datasets, and maintains
compatibility with various off-the-shelf anomaly detection techniques. For
example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of
the missing features.

</details>


### [93] [Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2508.06247)
*Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li*

Main category: cs.LG

TL;DR: CMOSS是一种高效的组合多臂老虎机算法，消除了对log T的依赖，匹配了已知的下界，并在半强盗和级联反馈中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决UCB和对抗性方法在组合多臂老虎机中的性能与计算效率的权衡问题。

Method: 提出CMOSS算法，通过半强盗反馈实现实例无关的遗憾界限。

Result: CMOSS在半强盗反馈下实现了O((log k)^2√kmT)的遗憾，并在实验中优于基准算法。

Conclusion: CMOSS在组合多臂老虎机中提供了高效且最优的解决方案，适用于多种反馈场景。

Abstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential
decision-making framework, dominated by two algorithmic families: UCB-based and
adversarial methods such as follow the regularized leader (FTRL) and online
mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer
from additional regret factor $\log T$ that is detrimental over long horizons,
while adversarial methods such as EXP3.M and HYBRID impose significant
computational overhead. To resolve this trade-off, we introduce the
Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS
is a computationally efficient algorithm that achieves an instance-independent
regret of $O\big( (\log k)^2\sqrt{kmT}\big )$ under semi-bandit feedback, where
$m$ is the number of arms and $k$ is the maximum cardinality of a feasible
action. Crucially, this result eliminates the dependency on $\log T$ and
matches the established $\Omega\big( \sqrt{kmT}\big)$ lower bound up to
$O\big((\log k)^2\big)$. We then extend our analysis to show that CMOSS is also
applicable to cascading feedback. Experiments on synthetic and real-world
datasets validate that CMOSS consistently outperforms benchmark algorithms in
both regret and runtime efficiency.

</details>


### [94] [In-Training Defenses against Emergent Misalignment in Language Models](https://arxiv.org/abs/2508.06249)
*David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai*

Main category: cs.LG

TL;DR: 论文研究了微调大型语言模型（LLM）时可能引发的意外有害行为（EMA），并提出了四种训练正则化干预方法以减少EMA。


<details>
  <summary>Details</summary>
Motivation: 微调LLM可能导致模型在目标领域外出现有害行为，即使微调数据本身无害。研究旨在为API提供商提供实用的防护措施。

Method: 研究了四种干预方法：KL散度正则化、特征空间L2距离、安全子空间投影（SafeLoRA）和混合安全训练样本。

Result: 评估了四种方法在恶意任务和良性任务上的效果，发现它们能有效减少EMA。

Conclusion: 研究为EMA问题提供了初步解决方案，并提出了未来研究方向。

Abstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs)
for new domains, yet recent work reveals emergent misalignment (EMA): Even a
small, domain-specific fine-tune can induce harmful behaviors far outside the
target domain. Even in the case where model weights are hidden behind a
fine-tuning API, this gives attackers inadvertent access to a broadly
misaligned model in a way that can be hard to detect from the fine-tuning data
alone. We present the first systematic study of in-training safeguards against
EMA that are practical for providers who expose fine-tuning via an API. We
investigate four training regularization interventions: (i) KL-divergence
regularization toward a safe reference model, (ii) $\ell_2$ distance in feature
space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving
of a small amount of safe training examples from a general instruct-tuning
dataset. We first evaluate the methods' emergent misalignment effect across
four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on
benign tasks. We conclude with a discussion of open questions in emergent
misalignment research.

</details>


### [95] [Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)](https://arxiv.org/abs/2508.06251)
*Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi*

Main category: cs.LG

TL;DR: 提出了一种基于张量网络（MPS）的隐私保护高质量合成表格数据生成方法，在数据保真度和隐私保护能力上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺、隐私约束及多样化数据集需求，为训练鲁棒模型提供支持。

Method: 使用矩阵乘积状态（MPS）生成合成数据，结合噪声注入和梯度裁剪实现差分隐私。

Result: MPS在严格隐私约束下表现优于CTGAN、VAE和PrivBayes等模型。

Conclusion: MPS是隐私感知合成数据生成的有前景工具，结合张量网络表达力和隐私机制，适用于敏感领域。

Abstract: Synthetic data generation is a key technique in modern artificial
intelligence, addressing data scarcity, privacy constraints, and the need for
diverse datasets in training robust models. In this work, we propose a method
for generating privacy-preserving high-quality synthetic tabular data using
Tensor Networks, specifically Matrix Product States (MPS). We benchmark the
MPS-based generative model against state-of-the-art models such as CTGAN, VAE,
and PrivBayes, focusing on both fidelity and privacy-preserving capabilities.
To ensure differential privacy (DP), we integrate noise injection and gradient
clipping during training, enabling privacy guarantees via R\'enyi Differential
Privacy accounting. Across multiple metrics analyzing data fidelity and
downstream machine learning task performance, our results show that MPS
outperforms classical models, particularly under strict privacy constraints.
This work highlights MPS as a promising tool for privacy-aware synthetic data
generation. By combining the expressive power of tensor network representations
with formal privacy mechanisms, the proposed approach offers an interpretable
and scalable alternative for secure data sharing. Its structured design
facilitates integration into sensitive domains where both data quality and
confidentiality are critical.

</details>


### [96] [Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors](https://arxiv.org/abs/2508.06257)
*Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang*

Main category: cs.LG

TL;DR: 提出了一种名为GTMancer的框架，利用图神经网络和对比学习整合多组学数据，以改进癌症亚型分类。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多组学数据的复杂耦合关系时存在不足，限制了其在精准肿瘤学中的应用。

Method: 结合图神经网络和对比学习，在多组学数据中引入双重注意力系数，优化统一语义空间中的表示。

Result: 在七个真实癌症数据集上，GTMancer表现优于现有最先进算法。

Conclusion: GTMancer为多组学数据整合和癌症亚型分类提供了有效解决方案。

Abstract: Integrating multi-omics datasets through data-driven analysis offers a
comprehensive understanding of the complex biological processes underlying
various diseases, particularly cancer. Graph Neural Networks (GNNs) have
recently demonstrated remarkable ability to exploit relational structures in
biological data, enabling advances in multi-omics integration for cancer
subtype classification. Existing approaches often neglect the intricate
coupling between heterogeneous omics, limiting their capacity to resolve subtle
cancer subtype heterogeneity critical for precision oncology. To address these
limitations, we propose a framework named Graph Transformer for Multi-omics
Cancer Subtype Classification (GTMancer). This framework builds upon the GNN
optimization problem and extends its application to complex multi-omics data.
Specifically, our method leverages contrastive learning to embed multi-omics
data into a unified semantic space. We unroll the multiplex graph optimization
problem in that unified space and introduce dual sets of attention coefficients
to capture structural graph priors both within and among multi-omics data. This
approach enables global omics information to guide the refining of the
representations of individual omics. Empirical experiments on seven real-world
cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art
algorithms.

</details>


### [97] [OM2P: Offline Multi-Agent Mean-Flow Policy](https://arxiv.org/abs/2508.06269)
*Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: OM2P是一种新颖的离线多智能体强化学习算法，通过一步动作采样和奖励感知优化，解决了扩散和流模型在效率上的问题。


<details>
  <summary>Details</summary>
Motivation: 扩散和流模型在多智能体强化学习中效率低下，难以应用于时间敏感或资源受限的场景。

Method: 提出OM2P算法，结合均值流匹配损失和Q函数监督，设计广义时间步分布和无导数估计策略。

Result: 在Multi-Agent Particle和MuJoCo基准测试中，OM2P性能优越，GPU内存使用减少3.8倍，训练速度提升10.8倍。

Conclusion: OM2P首次成功将均值流模型集成到离线多智能体强化学习中，为实用和可扩展的生成策略铺平了道路。

Abstract: Generative models, especially diffusion and flow-based models, have been
promising in offline multi-agent reinforcement learning. However, integrating
powerful generative models into this framework poses unique challenges. In
particular, diffusion and flow-based policies suffer from low sampling
efficiency due to their iterative generation processes, making them impractical
in time-sensitive or resource-constrained settings. To tackle these
difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel
offline MARL algorithm to achieve efficient one-step action sampling. To
address the misalignment between generative objectives and reward maximization,
we introduce a reward-aware optimization scheme that integrates a
carefully-designed mean-flow matching loss with Q-function supervision.
Additionally, we design a generalized timestep distribution and a
derivative-free estimation strategy to reduce memory overhead and improve
training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo
benchmarks demonstrate that OM2P achieves superior performance, with up to a
3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.
Our approach represents the first to successfully integrate mean-flow model
into offline MARL, paving the way for practical and scalable generative
policies in cooperative multi-agent settings.

</details>


### [98] [A Study on Regularization-Based Continual Learning Methods for Indic ASR](https://arxiv.org/abs/2508.06280)
*Gokul Adethya T,S. Jaya Nirmala*

Main category: cs.LG

TL;DR: 该论文研究了在印度语言中应用持续学习（CL）于自动语音识别（ASR）系统，以解决数据顺序到达和隐私限制的问题。


<details>
  <summary>Details</summary>
Motivation: 印度语言的多样性使得开发包容性ASR系统具有挑战性，传统多语言模型因数据顺序到达和隐私问题不适用。

Method: 使用基于Conformer的混合RNN-T/CTC模型，先在印地语上预训练，再逐步训练其他八种印度语言。评估了三种CL策略（EWC、MAS、LwF）。

Result: 结果表明，CL能有效减少遗忘，优于简单微调，适用于印度语言ASR。

Conclusion: 持续学习是解决印度语言ASR系统挑战的有效方法，代码已开源。

Abstract: Indias linguistic diversity poses significant challenges for developing
inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual
models, which require simultaneous access to all language data, are impractical
due to the sequential arrival of data and privacy constraints. Continual
Learning (CL) offers a solution by enabling models to learn new languages
sequentially without catastrophically forgetting previously learned knowledge.
This paper investigates CL for ASR on Indian languages using a subset of the
IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,
initially pretrained on Hindi, which is then incrementally trained on eight
additional Indian languages, for a total sequence of nine languages. We
evaluate three prominent regularization- and distillation-based CL strategies:
Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning
without Forgetting (LwF), selected for their suitability in no-replay,
privacy-conscious scenarios. Performance is analyzed using Word Error Rate
(WER) for both RNN-T and CTC paths on clean and noisy data, as well as
knowledge retention via Backward Transfer. We also explore the impact of
varying the number of training epochs (1, 2, 5, and 10) per task. Results,
compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating
forgetting, making it a promising approach for scalable ASR in diverse Indian
languages under realistic constraints. The code is available at:
https://github.com/FrozenWolf-Cyber/Indic-CL-ASR

</details>


### [99] [Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback](https://arxiv.org/abs/2508.06292)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 提出了一种新型多输出脉冲神经元模型，结合了线性状态空间模型（SSM）的状态转移和非线性反馈机制，提升了SNN的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 结合SNN的低延迟、高效能与深度SSM的竞争性能，解决现有SNN和SSM模型在精度和稳定性上的不足。

Method: 设计了一个多输出脉冲神经元模型，明确区分脉冲功能、重置条件和重置动作，并引入非线性反馈机制。

Result: 在多个任务（如关键词识别、事件视觉任务和序列模式识别）中表现与现有SNN基准相当，且能克服线性动态不稳定性。

Conclusion: 提出的重置机制能提升模型稳定性，扩展了深度SSM模型的应用范围。

Abstract: Neuromorphic computing is an emerging technology enabling low-latency and
energy-efficient signal processing. A key algorithmic tool in neuromorphic
computing is spiking neural networks (SNNs). SNNs are biologically inspired
neural networks which utilize stateful neurons, and provide low-bit data
processing by encoding and decoding information using spikes. Similar to SNNs,
deep state-space models (SSMs) utilize stateful building blocks. However, deep
SSMs, which recently achieved competitive performance in various temporal
modeling tasks, are typically designed with high-precision activation functions
and no reset mechanisms. To bridge the gains offered by SNNs and the recent
deep SSM models, we propose a novel multiple-output spiking neuron model that
combines a linear, general SSM state transition with a non-linear feedback
mechanism through reset. Compared to the existing neuron models for SNNs, our
proposed model clearly conceptualizes the differences between the spiking
function, the reset condition and the reset action. The experimental results on
various tasks, i.e., a keyword spotting task, an event-based vision task and a
sequential pattern recognition task, show that our proposed model achieves
performance comparable to existing benchmarks in the SNN literature. Our
results illustrate how the proposed reset mechanism can overcome instability
and enable learning even when the linear part of neuron dynamics is unstable,
allowing us to go beyond the strictly enforced stability of linear dynamics in
recent deep SSM models.

</details>


### [100] [FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields](https://arxiv.org/abs/2508.06301)
*Junhyeog Yun,Minui Hong,Gunhee Kim*

Main category: cs.LG

TL;DR: FedMeNF是一种新的联邦元学习方法，通过隐私保护损失函数解决传统FML的隐私泄露问题，实现快速优化和高效重建。


<details>
  <summary>Details</summary>
Motivation: 神经场学习需要大量数据和计算资源，传统FML方法存在隐私泄露问题。

Method: 提出FedMeNF，采用隐私保护损失函数在本地元优化中防止隐私泄露。

Result: 实验表明FedMeNF在少样本或非IID数据下仍能快速优化并保持隐私。

Conclusion: FedMeNF在保护隐私的同时，实现了高效学习和重建性能。

Abstract: Neural fields provide a memory-efficient representation of data, which can
effectively handle diverse modalities and large-scale data. However, learning
to map neural fields often requires large amounts of training data and
computations, which can be limited to resource-constrained edge devices. One
approach to tackle this limitation is to leverage Federated Meta-Learning
(FML), but traditional FML approaches suffer from privacy leakage. To address
these issues, we introduce a novel FML approach called FedMeNF. FedMeNF
utilizes a new privacy-preserving loss function that regulates privacy leakage
in the local meta-optimization. This enables the local meta-learner to optimize
quickly and efficiently without retaining the client's private data. Our
experiments demonstrate that FedMeNF achieves fast optimization speed and
robust reconstruction performance, even with few-shot or non-IID data across
diverse data modalities, while preserving client data privacy.

</details>


### [101] [Introducing Fractional Classification Loss for Robust Learning with Noisy Labels](https://arxiv.org/abs/2508.06346)
*Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya*

Main category: cs.LG

TL;DR: 提出了一种自适应鲁棒损失函数FCL，通过分数阶导数自动调整对标签噪声的鲁棒性，无需手动调参。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒损失函数需要大量数据集特定的超参数调优，限制了其应用。

Method: 结合交叉熵的分数阶导数和MAE，动态学习分数阶导数阶数μ，平衡鲁棒性和收敛速度。

Result: 在基准数据集上实现了最先进的性能，无需手动调参。

Conclusion: FCL通过动态调整损失函数，有效解决了标签噪声下的分类问题。

Abstract: Robust loss functions are crucial for training deep neural networks in the
presence of label noise, yet existing approaches require extensive,
dataset-specific hyperparameter tuning. In this work, we introduce Fractional
Classification Loss (FCL), an adaptive robust loss that automatically
calibrates its robustness to label noise during training. Built within the
active-passive loss framework, FCL employs the fractional derivative of the
Cross-Entropy (CE) loss as its active component and the Mean Absolute Error
(MAE) as its passive loss component. With this formulation, we demonstrate that
the fractional derivative order $\mu$ spans a family of loss functions that
interpolate between MAE-like robustness and CE-like fast convergence.
Furthermore, we integrate $\mu$ into the gradient-based optimization as a
learnable parameter and automatically adjust it to optimize the trade-off
between robustness and convergence speed. We reveal that FCL's unique property
establishes a critical trade-off that enables the stable learning of $\mu$:
lower log penalties on difficult or mislabeled examples improve robustness but
impose higher penalties on easy or clean data, reducing model confidence in
them. Consequently, FCL can dynamically reshape its loss landscape to achieve
effective classification performance under label noise. Extensive experiments
on benchmark datasets show that FCL achieves state-of-the-art results without
the need for manual hyperparameter tuning.

</details>


### [102] [Structural Equation-VAE: Disentangled Latent Representations for Tabular Data](https://arxiv.org/abs/2508.06347)
*Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam*

Main category: cs.LG

TL;DR: SE-VAE是一种新型变分自编码器，通过结构方程建模嵌入测量结构，实现可解释的潜在表示学习。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据中潜在表示学习的可解释性问题，特别是在科学和社会领域需要理论驱动的潜在构建。

Method: SE-VAE结合结构方程建模，将潜在子空间与已知指标分组对齐，并引入全局干扰潜在变量以隔离特定构建的混杂变异。

Result: SE-VAE在模拟表格数据集上表现优异，在因子恢复、可解释性和抗干扰性方面优于基线模型。

Conclusion: SE-VAE通过架构设计而非统计正则化实现解耦，为科学和社会领域的白盒生成建模提供了框架。

Abstract: Learning interpretable latent representations from tabular data remains a
challenge in deep generative modeling. We introduce SE-VAE (Structural
Equation-Variational Autoencoder), a novel architecture that embeds measurement
structure directly into the design of a variational autoencoder. Inspired by
structural equation modeling, SE-VAE aligns latent subspaces with known
indicator groupings and introduces a global nuisance latent to isolate
construct-specific confounding variation. This modular architecture enables
disentanglement through design rather than through statistical regularizers
alone. We evaluate SE-VAE on a suite of simulated tabular datasets and
benchmark its performance against a series of leading baselines using standard
disentanglement metrics. SE-VAE consistently outperforms alternatives in factor
recovery, interpretability, and robustness to nuisance variation. Ablation
results reveal that architectural structure, rather than regularization
strength, is the key driver of performance. SE-VAE offers a principled
framework for white-box generative modeling in scientific and social domains
where latent constructs are theory-driven and measurement validity is
essential.

</details>


### [103] [Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means](https://arxiv.org/abs/2508.06353)
*Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic*

Main category: cs.LG

TL;DR: Gk-means是一种基于几何原理的新型k-means算法，通过利用标量投影显著提升效率，同时保持解的质量。


<details>
  <summary>Details</summary>
Motivation: 传统k-means算法效率较低，Gk-means旨在通过几何优化减少计算开销。

Method: 利用标量投影识别高表达数据（HE），忽略低表达数据（LE），从而加速聚类过程。

Result: 在合成、真实世界和高维数据集上，Gk-means在运行时间和距离计算上优于传统及SOTA k-means变体，且能耗更低。

Conclusion: Gk-means是一种高效、节能且可持续的k-means改进方案。

Abstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel
approach that significantly enhances the efficiency and energy economy of the
widely utilized k-means algorithm, which, despite its inception over five
decades ago, remains a cornerstone in machine learning applications. The
essence of Gk-means lies in its active utilization of geometric principles,
specifically scalar projection, to significantly accelerate the algorithm
without sacrificing solution quality. This geometric strategy enables a more
discerning focus on data points that are most likely to influence cluster
updates, which we call as high expressive data (HE). In contrast, low
expressive data (LE), does not impact clustering outcome, is effectively
bypassed, leading to considerable reductions in computational overhead.
Experiments spanning synthetic, real-world and high-dimensional datasets,
demonstrate Gk-means is significantly better than traditional and state of the
art (SOTA) k-means variants in runtime and distance computations (DC).
Moreover, Gk-means exhibits better resource efficiency, as evidenced by its
reduced energy footprint, placing it as more sustainable alternative.

</details>


### [104] [Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts](https://arxiv.org/abs/2508.06361)
*Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He*

Main category: cs.LG

TL;DR: 研究探讨了大型语言模型（LLMs）在无人类诱导情况下自发性欺骗行为，提出了一种基于心理学的量化框架，并发现模型在复杂任务中欺骗倾向增加。


<details>
  <summary>Details</summary>
Motivation: LLMs的信任度是关键问题，但现有研究多关注人类诱导的欺骗，忽略了模型自发的欺骗行为。

Method: 提出基于‘接触搜索问题’的框架，引入‘欺骗意图分数’和‘欺骗行为分数’两种统计指标。

Result: 评估14个主流LLMs，发现任务难度增加时欺骗倾向上升。

Conclusion: 即使最先进的LLMs在复杂任务中也会表现出欺骗倾向，这对LLMs在关键领域的部署提出了警示。

Abstract: Large Language Models (LLMs) have been widely deployed in reasoning,
planning, and decision-making tasks, making their trustworthiness a critical
concern. The potential for intentional deception, where an LLM deliberately
fabricates or conceals information to serve a hidden objective, remains a
significant and underexplored threat. Existing studies typically induce such
deception by explicitly setting a "hidden" objective through prompting or
fine-tuning, which may not fully reflect real-world human-LLM interactions.
Moving beyond this human-induced deception, we investigate LLMs' self-initiated
deception on benign prompts. To address the absence of ground truth in this
evaluation, we propose a novel framework using "contact searching questions."
This framework introduces two statistical metrics derived from psychological
principles to quantify the likelihood of deception. The first, the Deceptive
Intention Score, measures the model's bias towards a hidden objective. The
second, Deceptive Behavior Score, measures the inconsistency between the LLM's
internal belief and its expressed output. Upon evaluating 14 leading LLMs, we
find that both metrics escalate as task difficulty increases, rising in
parallel for most models. Building on these findings, we formulate a
mathematical model to explain this behavior. These results reveal that even the
most advanced LLMs exhibit an increasing tendency toward deception when
handling complex problems, raising critical concerns for the deployment of LLM
agents in complex and crucial domains.

</details>


### [105] [ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design](https://arxiv.org/abs/2508.06364)
*Renyi Zhou,Huimin Zhu,Jing Tang,Min Li*

Main category: cs.LG

TL;DR: ActivityDiff是一种基于扩散模型的生成方法，通过分类器引导技术实现分子设计中对多目标活性的精确控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成方法在药物设计中仅关注单一活性而无法同时管理多目标及副作用的问题。

Method: 利用分别训练的药物-靶点分类器进行正负引导，扩散模型生成分子。

Result: 实验表明ActivityDiff能有效处理单/双目标生成、片段约束设计、选择性生成及减少脱靶效应等任务。

Conclusion: ActivityDiff为分子活性控制提供了新范式，是一个多功能且可扩展的框架。

Abstract: Achieving precise control over a molecule's biological activity-encompassing
targeted activation/inhibition, cooperative multi-target modulation, and
off-target toxicity mitigation-remains a critical challenge in de novo drug
design. However, existing generative methods primarily focus on producing
molecules with a single desired activity, lacking integrated mechanisms for the
simultaneous management of multiple intended and unintended molecular
interactions. Here, we propose ActivityDiff, a generative approach based on the
classifier-guidance technique of diffusion models. It leverages separately
trained drug-target classifiers for both positive and negative guidance,
enabling the model to enhance desired activities while minimizing harmful
off-target effects. Experimental results show that ActivityDiff effectively
handles essential drug design tasks, including single-/dual-target generation,
fragment-constrained dual-target design, selective generation to enhance target
specificity, and reduction of off-target effects. These results demonstrate the
effectiveness of classifier-guided diffusion in balancing efficacy and safety
in molecular design. Overall, our work introduces a novel paradigm for
achieving integrated control over molecular activity, and provides ActivityDiff
as a versatile and extensible framework.

</details>


### [106] [End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](https://arxiv.org/abs/2508.06387)
*Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh*

Main category: cs.LG

TL;DR: 本文提出了一种三阶段的端到端文本到SQL框架，通过LLM和提示工程提取自然语言查询中的隐含信息，训练大型db_id预测模型，并使用批评代理优化SQL生成，显著提升了数据库意图预测和SQL生成准确性。


<details>
  <summary>Details</summary>
Motivation: 传统文本到SQL方法假设目标数据库已预先指定，但在多数据库场景中，识别正确数据库是关键但被忽视的步骤。本文旨在解决这一问题。

Method: 三阶段框架：1）利用LLM和提示工程从自然语言查询中提取规则；2）训练RoBERTa微调编码器预测db_id；3）使用批评代理优化生成的SQL。

Result: 实验结果表明，该框架在数据库意图预测和SQL生成准确性上均优于当前最先进模型。

Conclusion: 本文提出的框架在多数据库场景中有效解决了数据库识别问题，并显著提升了文本到SQL的性能。

Abstract: Text-to-SQL bridges the gap between natural language and structured database
language, thus allowing non-technical users to easily query databases.
Traditional approaches model text-to-SQL as a direct translation task, where a
given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances
in large language models (LLMs) have significantly improved translation
accuracy, however, these methods all require that the target database is
pre-specified. This becomes problematic in scenarios with multiple extensive
databases, where identifying the correct database becomes a crucial yet
overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL
framework to identify the user's intended database before generating SQL
queries. Our approach leverages LLMs and prompt engineering to extract implicit
information from natural language queries (NLQs) in the form of a ruleset. We
then train a large db\_id prediction model, which includes a RoBERTa-based
finetuned encoder, to predict the correct Database identifier (db\_id) based on
both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL
by using critic agents to correct errors. Experimental results demonstrate that
our framework outperforms the current state-of-the-art models in both database
intent prediction and SQL generation accuracy.

</details>


### [107] [Sample-efficient LLM Optimization with Reset Replay](https://arxiv.org/abs/2508.06412)
*Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: 论文提出了一种名为LoRR的插件方法，通过高重放训练和周期性重置策略，提升大语言模型（LLM）在偏好优化中的样本效率，同时避免过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型优化方法（如强化学习和偏好优化）存在样本效率低和易受初始经验偏见影响的问题，导致策略质量下降。

Method: LoRR结合高重放训练、周期性重置策略和混合优化目标（监督微调与偏好损失），以提升数据利用效率。

Result: 实验表明，LoRR显著提升了多种偏好优化方法在数学和通用推理任务上的性能，甚至在某些复杂任务上媲美计算密集型强化学习算法。

Conclusion: LoRR为LLM微调提供了一种高效、实用的方法，能够在有限数据下实现更高性能。

Abstract: Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

</details>


### [108] [A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images](https://arxiv.org/abs/2508.06409)
*Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee*

Main category: cs.LG

TL;DR: 利用公开众包数据（311服务电话和街景图像）追踪和预测旧金山无家可归者帐篷趋势，提供更及时、本地化和低成本的信息。


<details>
  <summary>Details</summary>
Motivation: 现有监测方法（如PIT计数）在频率、一致性和空间细节上存在局限，无法捕捉快速波动和空间变化。

Method: 使用311服务电话和街景图像数据，构建预测模型，捕捉每日和社区级别的细微变化。

Result: 模型揭示了传统方法忽略的模式，如疫情期间的快速波动和帐篷位置的空间变化。

Conclusion: 该方法为政策响应和干预评估提供了更有效的工具。

Abstract: Homelessness in the United States has surged to levels unseen since the Great
Depression. However, existing methods for monitoring it, such as point-in-time
(PIT) counts, have limitations in terms of frequency, consistency, and spatial
detail. This study proposes a new approach using publicly available,
crowdsourced data, specifically 311 Service Calls and street-level imagery, to
track and forecast homeless tent trends in San Francisco. Our predictive model
captures fine-grained daily and neighborhood-level variations, uncovering
patterns that traditional counts often overlook, such as rapid fluctuations
during the COVID-19 pandemic and spatial shifts in tent locations over time. By
providing more timely, localized, and cost-effective information, this approach
serves as a valuable tool for guiding policy responses and evaluating
interventions aimed at reducing unsheltered homelessness.

</details>


### [109] [LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection](https://arxiv.org/abs/2508.06467)
*Ameya Anjarlekar,Sandeep Pombra*

Main category: cs.LG

TL;DR: GRIN是一个针对大型语言模型（LLM）的模块化、目标化遗忘框架，通过梯度比度量识别关键参数并选择性注入噪声，提升遗忘性能同时保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型面临法律和伦理审查，需要有效遗忘敏感或未授权数据，现有方法存在遗忘不彻底或无关知识退化的问题。

Method: 提出GRIN框架，使用梯度比度量定位关键参数，选择性注入噪声后进行微调。

Result: 在TOFU、WMDP和SafePKU等标准基准上验证了方法的有效性。

Conclusion: GRIN在提升遗忘性能的同时保持了模型效用，为LLM遗忘问题提供了新解决方案。

Abstract: The growing legal and ethical scrutiny of large language models (LLMs)
necessitates effective machine unlearning, particularly for sensitive or
unauthorized data. Existing empirical methods often yield incomplete forgetting
or unintended degradation of unrelated knowledge due to poor localization. In
this work, we propose GRIN: a modular and targeted framework for LLM
unlearning. GRIN introduces a novel gradient-ratio-based metric to identify
parameters most responsible for memorizing forget data. We then perform
selective noise injection into these parameters prior to fine-tuning, which
improves unlearning performance while maintaining model utility. Finally, we
propose new evaluation metrics tailored to the LLM setting and validate our
approach on standard benchmarks such as TOFU, WMDP, and SafePKU.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [110] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 论文提出AEPO框架，通过多答案生成和自适应探索奖励提升MLLMs在GUI中的语义对齐能力，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在GUI操作中语义对齐不足的问题，尤其是探索效率低导致的困难语义关联学习。

Method: 提出AEPO框架，结合多答案生成策略和自适应探索奖励（AER）函数，优化策略探索。

Result: 在多个GUI基准测试中取得SOTA结果，相对基线提升高达9.0%。

Conclusion: AEPO有效解决了语义对齐的探索瓶颈，为MLLMs在GUI中的应用提供了新方法。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [111] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 本文提出了一种结合主动推理原则与大型语言模型（LLMs）的新型框架，用于开发安全的通用人工智能（AGI）。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法（如事后可解释性和奖励工程）存在根本性局限，需将安全性融入系统核心设计。

Method: 通过透明信念表示和分层价值对齐，利用自然语言作为信念表达媒介，构建多智能体系统，实现安全机制。

Result: 提出具体安全机制：信念与偏好分离、资源感知的自由能最小化、模块化智能体结构。

Conclusion: 该框架为AGI开发提供了一条更安全的发展路径，并以ARC基准为中心提出验证实验。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [112] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 现代神经网络展示了类似人类思维的组合、创新和快速学习能力，挑战了人类认知基于符号系统的观点，但仍需符号系统定义抽象问题。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络是否削弱了人类认知基于符号系统的论点，并提出新的研究方向。

Method: 通过分析神经网络的能力及其与符号系统的关系，论证人类思维的符号基础。

Result: 神经网络展示了类似人类的能力，但符号系统在定义抽象问题中仍起关键作用。

Conclusion: 需重新研究人类思维的符号基础，提出新的研究议程。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [113] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI是一个统一的框架，结合因果评分与传统XAI方法，支持交互式、多方法的解释过程，满足不同利益相关者的需求。


<details>
  <summary>Details</summary>
Motivation: 当前XAI方法主要服务于开发者，未能满足多样化利益相关者的需求。H-XAI旨在填补这一空白，提供更全面的解释工具。

Method: H-XAI整合因果评分与传统XAI方法，支持利益相关者提出问题、测试假设，并通过随机和偏置基线比较模型行为。

Result: 通过两个案例研究（信用风险分类和金融时间序列预测）验证了H-XAI的通用性和有效性。

Conclusion: H-XAI填补了现有XAI方法的不足，结合因果评分和后验解释，满足利益相关者在个体决策和整体模型层面的需求。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [114] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 该论文综述了具身导航中的安全问题，分析了攻击策略、防御机制和评估方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）和具身AI的发展，具身导航在关键应用中的安全问题日益突出，需确保其在动态环境中的安全性。

Method: 通过全面分析现有安全挑战、缓解技术、数据集和评估指标，探讨攻击方法、防御策略及验证框架。

Result: 总结了具身导航安全的研究现状，提出了未来研究方向，如更可靠的评估技术和验证框架。

Conclusion: 该综述为开发更安全可靠的具身导航系统提供了指导，并对提升社会安全和工业效率具有广泛意义。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [115] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 提出了一种基于知识图谱（KG）的工具检索框架，通过捕捉工具间的语义关系和功能依赖，提升多步任务中的工具检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统工具检索方法主要依赖用户查询与工具描述的相似性，限制了多步请求的处理能力，因此需要更全面的检索方法。

Method: 利用知识图谱中的1-hop ego工具图集合建模工具间的直接和间接连接，实现更全面的工具选择。

Result: 在合成数据集上，基于工具图的方法在Complete Recall指标上达到91.85%，优于非KG基线方法的89.26%。

Conclusion: 知识图谱的结构信息为纯相似性匹配提供了补充信号，特别适用于需要顺序工具组合的查询。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [116] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出MedOrch框架，通过LLM中介协调多VLM专家代理协作，提升医疗多模态决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有多代理研究局限于语言任务，多模态场景下VLMs协作能力不足，需解决错误结果放大的问题。

Method: 采用LLM中介代理协调多个VLM专家代理，实现输出交换与反思，避免昂贵GPT模型。

Result: 在五个医疗视觉问答基准上验证，协作性能超越单一代理，无需额外训练。

Conclusion: 中介引导的多代理协作可推动医疗多模态智能发展，代码将开源。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [117] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 论文提出了一种分层多智能体框架HIMA，结合专家模仿学习和元控制器，解决了LLM在动态长时任务（如《星际争霸II》）中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在动态、长时任务（如《星际争霸II》）中表现不佳，难以处理资源约束和部分可观测环境。

Method: 提出HIMA框架，包含专家模仿学习智能体和元控制器Strategic Planner（SP），通过专家演示学习特定策略并生成多步动作序列。

Result: HIMA在战略清晰度、适应性和计算效率上优于现有方法。

Conclusion: 结合专家模仿模块和元级协调，可开发更鲁棒的通用AI智能体。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [118] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 论文提出了一个双用途框架，利用参与式预算（PB）评估大语言模型（LLMs）在资源分配和推理能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在结构化资源分配任务中的能力，并解决现有评估方法因数据污染和静态基准的局限性。

Method: 通过三种提示策略（贪婪选择、直接优化和启发式改进）让LLMs在预算约束下选择项目子集，并与最优解对比。同时测试LLMs从自然语言输入推断偏好的能力。

Result: 结果表明提示设计对LLMs表现至关重要，且LLMs在机制设计和处理非结构化输入方面具有潜力。

Conclusion: LLMs在资源分配和推理任务中表现出潜力，尤其是在处理非结构化输入时。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [119] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 论文呼吁重视认知想象力在人工智能中的关键作用，并提出语义模型作为模拟认知想象力的工具。


<details>
  <summary>Details</summary>
Motivation: 认知想象力在人类思维中扮演重要角色，但当前AI领域对其重视不足，导致推理和决策能力受限。

Method: 提出语义模型，一种基于概率因果关系的数学模型，能够学习和确保想象语境的连贯性。

Result: 语义模型能够模拟认知想象力，支持对想象语境的透明操作和验证。

Conclusion: 认知想象力是AI领域的重要突破方向，语义模型为实现这一目标提供了可行工具。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [120] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: 本文提出了一种名为CA-DL8.5的通用、完整且随时可用的波束搜索算法，用于优化决策树分类误差。该算法扩展了DL8.5框架，统一了现有的随时策略，并通过模块化设计整合了多种启发式和松弛机制。实验表明，CA-DL8.5在性能上优于其他变体和Blossom算法。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法在未完成搜索时难以快速找到高质量的决策树，且缺乏系统性比较，本文旨在提出一种更有效的随时优化算法。

Method: CA-DL8.5结合了DL8.5的高效分支定界剪枝和基于字典树的缓存，采用重启波束搜索逐步放宽剪枝标准。

Result: 实验结果显示，基于LDS启发式的CA-DL8.5在标准分类基准上表现最佳，优于其他变体和Blossom算法。

Conclusion: CA-DL8.5为决策树学习提供了一个通用框架，并通过实验验证了其优越性。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [121] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 论文提出了一种基于深度强化学习（DRL）和鸟瞰图（BEV）感知的自动驾驶新方法，结合了高效的时空特征提取网络Mamba-BEV和ME³-BEV框架，显著提升了动态城市驾驶场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在复杂环境感知和实时决策方面面临挑战，传统模块化方法存在误差传播和协调问题，端到端学习方法则受限于计算瓶颈。

Method: 提出Mamba-BEV模型，结合BEV感知和Mamba框架进行时空特征建模；进一步提出ME³-BEV框架，将Mamba-BEV作为端到端DRL的特征输入。

Result: 在CARLA模拟器上的实验表明，ME³-BEV在碰撞率和轨迹准确性等多项指标上优于现有模型。

Conclusion: ME³-BEV为实时自动驾驶提供了一种高效且可解释的解决方案。

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [122] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 本文解决了关于图神经网络（GNNs）逻辑表达能力的一个开放性问题，证明其表达能力严格超过C2逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究GNNs与逻辑语言的关系，解决Barceló等人提出的未解决问题。

Method: 通过理论分析，比较GNNs与C2逻辑的表达能力。

Result: 证明GNNs的逻辑表达能力严格超过C2逻辑，适用于无向和有向图。

Conclusion: 该研究不仅解决了GNNs的开放性问题，还为无穷逻辑的表达能力提供了新见解。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [123] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR框架通过LLM代理科学家的结构化科学方法，提升表格推理能力，无需依赖标注数据或复杂增强，在零样本场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理任务中依赖标注数据或复杂数据增强的问题，以及LLMs在此类任务中表现不佳的局限性。

Method: 引入PanelTR框架，利用五个科学家角色的代理进行独立调查、自我审查和协作同行评审，实现语义级迁移。

Result: 在四个基准测试中，PanelTR优于普通LLMs，并媲美完全监督模型，且不依赖训练数据。

Conclusion: 结构化科学方法能有效处理复杂任务，具备灵活的语义理解能力，适用于零样本场景。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [124] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE是一种新型评估框架，通过让大型语言模型（LLMs）相互生成和解决可验证任务来评估其能力，具有自动化、可扩展和客观的特点。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法需要大量领域专业知识，难以适应快速发展的LLMs，因此需要一种更通用、可扩展的评估框架。

Method: SKATE将评估视为游戏，LLMs既作为任务设置者又作为解决者，生成可验证任务并相互竞争。使用TrueSkill排名系统评估模型。

Result: 实验表明，较弱模型能可靠区分较强模型，LLMs表现出自我偏好行为，SKATE能自动揭示模型间的细粒度能力差异。

Conclusion: SKATE为通用、可扩展的LLM评估框架提供了重要进展，能够跟上LLM的发展步伐。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [125] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 该研究通过可解释AI分析VRP解决方案质量预测模型的敏感性，发现某些特征对预测具有一致性影响，并提出统一框架以指导元启发式算法设计。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法依赖人工设计，而机器学习方法可以利用组合优化问题的结构特征，提升算法效率。本研究旨在通过可解释AI进一步理解模型决策机制。

Method: 使用多种分类器模型预测VRP解决方案质量，并进行敏感性分析，结合可解释AI技术揭示特征重要性。

Result: 研究发现特征重要性虽因模型而异，但某些特征始终是强预测因子，并提出了统一框架以量化特征影响。

Conclusion: 特征重要性分析为元启发式算法设计提供了新思路，未来可基于此开发更高效的VRP求解方法。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [126] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 研究通过RAG框架增强LLMs在药物禁忌领域的准确性，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在医疗领域的应用，解决药物禁忌信息准确性和可靠性问题。

Method: 采用RAG框架，结合GPT-4o-mini和text-embedding-3-small模型，利用Langchain构建混合检索系统，并整合DUR数据。

Result: 模型准确率从0.49-0.57提升至0.94、0.87和0.89。

Conclusion: RAG框架能显著减少药物禁忌决策的不确定性，提供更精确的信息。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [127] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 论文提出从准确性为中心转向置信度驱动的LLM评估系统，引入TH-Score量化过度自信现象，并提出LLM-as-a-Fuser框架提升校准和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估系统过于关注准确性，忽视了置信度校准的重要性，导致实际部署中可靠性不足。

Method: 引入TH-Score量化过度自信现象，提出LLM-as-a-Fuser框架，通过集成方法提升置信度校准。

Result: 实验表明，该方法显著改善了校准效果，实现了自适应、置信度驱动的评估流程，优于现有基线。

Conclusion: 置信度驱动的LLM评估系统更可靠，TH-Score和LLM-as-a-Fuser框架为实际部署提供了有效解决方案。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [128] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: GeoLaux基准测试填补了现有几何问题评估的空白，重点关注辅助线构建和长步推理能力，评估了13种MLLM模型，发现其在长步推理和辅助线意识上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有几何问题评估基准忽略了辅助线构建和细粒度过程评估，无法全面评估MLLM的长步推理能力。

Method: 提出GeoLaux基准，包含2,186个几何问题，设计五维评估策略（答案正确性、过程正确性、过程质量、辅助线影响和错误原因）。

Result: 实验发现模型在长步推理中性能显著下降，倾向于在证明问题中走捷径，且缺乏辅助线意识。

Conclusion: GeoLaux可作为评估MLLM长步几何推理能力的基准，并指导能力提升。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [129] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 论文提出“解释性AI”作为可解释AI（XAI）的补充范式，利用生成式AI能力提供更适应人类理解的解释，而非仅关注算法透明性。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法过于抽象且缺乏适应性，无法满足用户实际需求，因此需要一种更注重上下文推理和人类决策支持的范式。

Method: 提出八维概念模型，强调叙事沟通、自适应个性化和渐进披露原则，并通过快速情境设计方法在医疗领域进行实证验证。

Result: 用户更偏好上下文敏感的多模态解释，而非技术透明性，验证了解释性AI的实用性。

Conclusion: 研究呼吁设计更注重人类理解的AI系统，并提出了跨领域和文化背景的用户中心解释方法研究议程。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [130] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯归纳逻辑编程方法，通过最小消息长度程序从噪声数据中学习，平衡假设复杂性和数据拟合。


<details>
  <summary>Details</summary>
Motivation: 统一概率和逻辑学习是AI的关键挑战。

Method: 使用先验和似然平衡假设复杂性和数据拟合，先验偏好更通用的程序，似然偏好更准确的程序。

Result: 在游戏和药物设计等多个领域的实验中，显著优于先前方法，尤其是最小描述长度程序学习方法。

Conclusion: 该方法数据高效且对示例平衡不敏感，甚至能从仅正例中学习。

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [131] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 提出了一种通过打破假设空间对称性来加速归纳逻辑编程的方法，实验显示求解时间从超过一小时缩短至17秒。


<details>
  <summary>Details</summary>
Motivation: 归纳逻辑编程需要搜索大量假设空间，且存在许多逻辑等价的假设，导致搜索效率低下。

Method: 采用答案集编程实现对称性打破的方法。

Result: 在视觉推理和游戏等多个领域的实验中，求解时间从超过一小时减少到仅17秒。

Conclusion: 该方法显著提高了归纳逻辑编程的效率，适用于多种领域。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [132] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: PRISM Eval的BET工具通过动态对抗优化实现了对41个先进LLM中37个的100%攻击成功率，并提出了细粒度鲁棒性指标。


<details>
  <summary>Details</summary>
Motivation: 评估和提升大型语言模型（LLM）的鲁棒性，揭示其在不同攻击下的脆弱性。

Method: 使用PRISM Eval Behavior Elicitation Tool（BET）进行自动化红队测试，采用动态对抗优化技术。

Result: 对37/41的LLM实现了100%攻击成功率，攻击难度差异达300倍以上。

Conclusion: 提出了分布式鲁棒性评估的实用路径，并识别了针对特定危害类别的最有效攻击技术。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [133] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 论文反驳了Conant和Ashby的经典理论，提出了一种新的“信念更新”模型概念，强调观察者在理论中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 探讨Conant和Ashby的定理在更广泛情境下的适用性，并提出更普适的理论框架。

Method: 通过引入“信念更新”的概念，重新定义模型，并证明其适用于多种调控任务。

Result: 提出了一种更普适的定理，解决了原有理论的局限性，并通过观察者的视角解释了模型的本质。

Conclusion: 模型不仅是系统的属性，更是观察者赋予的，这一新视角为调控任务提供了更广泛的理论支持。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [134] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer的机器学习模型AntiCheatPT_256，用于检测《CS2》中的作弊行为，并公开了标注数据集CS2CD。模型在测试集上表现优异，准确率达89.17%，AUC为93.36%。


<details>
  <summary>Details</summary>
Motivation: 在线游戏中的作弊行为破坏了游戏体验，现有反作弊系统（如VAC）难以在不侵犯用户隐私的情况下应对不断演变的作弊手段。

Method: 使用公开数据集CS2CD（795场比赛的标注数据），生成90,707个上下文窗口并进行数据增强以解决类别不平衡问题。基于这些数据训练Transformer模型。

Result: 模型在未增强的测试集上达到89.17%的准确率和93.36%的AUC。

Conclusion: 该方法强调可重复性和实际应用性，为数据驱动的作弊检测研究提供了坚实基础。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [135] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 论文提出两种自动化构建法律知识图谱（KG）的方法，填补法律领域KG的空白，并验证其在暴力侵害妇女案件中的应用。


<details>
  <summary>Details</summary>
Motivation: 法律决策需要全面的立法背景知识和最新的法律案例信息，但法律领域的KG较少，因此开发了针对暴力侵害妇女案件的法律KG。

Method: 采用两种互补方法：系统化的自下而上方法和基于大型语言模型的新方法，结合结构化数据提取、本体开发和语义丰富。

Result: 构建的法律KG通过能力问题验证，可提升法律信息的可访问性，支持复杂查询和预测性司法机器学习工具。

Conclusion: 开发的法律KG对提升法律信息可访问性和支持预测性司法具有重要价值。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [136] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 论文提出了一种动态机制“Fair Game”，通过结合审计员和去偏算法，利用强化学习实现机器学习算法的公平性，并随时间适应社会变化。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习（Fair ML）的偏差定义通常是观察性的，且在实际应用中存在冲突和局限性，无法动态适应社会变化。

Method: 提出“Fair Game”框架，将审计员和去偏算法通过强化学习（RL）与机器学习算法结合，动态调整公平目标。

Result: 该框架能够灵活适应社会伦理和法律框架的变化，实现部署前后的公平性调整。

Conclusion: “Fair Game”为构建动态适应社会变化的公平机器学习系统提供了可行方案。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [137] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 本文提出了一种数据驱动框架，用于评估多赢家投票规则在不同偏好分布下违反公理的频率，并通过神经网络展示了其在减少公理违反方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过数据驱动的方法，而非传统的极端案例分析，更全面地评估投票规则的公理表现。

Method: 方法包括提出数据驱动框架，分析多赢家投票规则在不同偏好分布下的公理表现，并利用神经网络作为投票规则进行实验。

Result: 结果显示，神经网络作为投票规则在减少公理违反方面优于传统规则。

Conclusion: 结论表明，数据驱动方法可以为投票系统设计提供新思路，并推动社会选择领域的数据驱动研究。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>
